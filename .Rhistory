library(here)
here::i_am("ThesisAnalysisV1.Rmd") # find directory where file is in
# install.packages("tidyverse")
library("tidyverse")
# install.packages("papaja")
library("papaja")
# install.packages("imputeTS")
library("imputeTS")
# install.packages("graphicalVAR")
library("graphicalVAR")
# install.packages("qgraph")
library("qgraph")
# install.packages("OpenMX")
library("OpenMx")
# r_refs("r-references.bib")
# Notation:
# ---------
#     data:   full data set used.
#             In chunks that manipulate the whole data set (eg., imputation, detrending) I reassign the manipulated data object to 'data', so that results can easily be rerun on not detrended / not imputed data by simply not evaluating the previous code chunk
#     p:      participant (itiration in loop)
#     v:      variable (itiration in loop)
#     d:      temporary data object in loop
# sessionInfo()
# -------------
# R version 4.0.3 (2020-10-10)
# Platform: x86_64-apple-darwin17.0 (64-bit)
# Running under: macOS Big Sur 10.16
# Chunk 2: readData
# read data
data <- read.csv(here("data", "dd100-proppert.csv"))
# data is in long format
N <- data$participantID %>% unique()
range(N) # 1 : 116
length(unique(N)) # 112
setdiff(1:116, N) # Participants  8, 25, 45, 92  had been excluded by original authors because more than 30% of responses were missing
# rename IDs for easier looping
data$participantID <- factor(data$participantID,
levels = unique(data$participantID),
labels = 1:length(unique(data$participantID))) %>%
as.numeric()
N <- data$participantID %>% unique() %>% max()
# Chunk 3: exludeMissing
# count nr of missing per px
idx_missing <- matrix(NA, N, 7)
colnames(idx_missing) <- c("ID", "CompletedTotal", "CompletedT1", "CompletedT2", "Include", "Var_Tasks_T1", "Var_Tasks_T2")
for (p in 1:N){
# ID
idx_missing[p,1] <- p
d <- filter(data, data$participantID == p)
# CompletedTotal
idx_missing[p,2] <-  unique(d$total.days)
d1 <-  filter(d, day.response %in% 1:50, missingResponse == 1)
# CompletedT1
idx_missing[p,3] <- dim(d1)[1]
d2 <-  filter(d, day.response %in% 51:100, missingResponse == 1)
# CompletedT2
idx_missing[p,4] <- dim(d2)[1]
#check var in tasks
d3 <- filter(d, day.response %in% 1:50)
idx_missing[p,6] <- var(d3$tasks, na.rm = T) > 0
d4 <- filter(d, day.response %in% 51:100)
idx_missing[p,7] <- var(d4$tasks, na.rm = T) > 0
# Include; TRUE if more than 70 responses overall, and more than 35 both T1 and T2
# ALSO EXCLUDING 6 PARTICIPANTS WITH ZERO VAR IN TASKS
idx_missing[p,5] <- idx_missing[p,2]>70 & idx_missing[p,3]>35 & idx_missing[p,4]>35 &       idx_missing[p,6]==T & idx_missing[p,7]==T
}
# included IDs
idx_missing <- idx_missing %>% as.data.frame() %>% filter(Include == TRUE)
# exclude participants
data <- filter(data, participantID %in% idx_missing$ID)
# rename IDs again for future looping
data$participantID <- factor(data$participantID,
levels = unique(data$participantID),
labels = 1:length(unique(data$participantID))) %>%
as.numeric()
# N: participants retained
N <- max(unique(data$participantID)) #87
# Chunk 4: logLoops
emaLabels <- labels(data[, 6:75])[[2]] # store labels of EMA variables
# empty dataa frame to log loop
log_loops <- data.frame(
ID = rep(c(1:N), each = length(emaLabels)),
emaVar = rep(seq_along(emaLabels), N),
emaLabels = rep(emaLabels, N)
)
# Chunk 5: varSelection1
# v = 1: first EMA Variable; data[ ,1:5] are columns in data before 1st EMA variable, thus we use 5+v in all loops itirating on data
# ShapiroWilk test stat: 0 = perfect normality, 1 = deviation from normality.
# Because we want to prioritize more normally distributed variables, we use 1-ShapiroWilk.
# As result, a higher rank statistic means better properties
# Proportion completed T1
log_loops$completed_T1 <- numeric( N * length(emaLabels) )
for (p in 1:N){
d <- filter(data, participantID==p, day.response %in% 1:50)
for ( v in seq_along(emaLabels)){
log_loops$completed_T1[(p-1)*length(emaLabels)+v] <- sum(!is.na(d[ ,5+v]))/50 # proportion completed
}
# Proportion completed T2
log_loops$completed_T2 <- numeric( N * length(emaLabels) )
for (p in 1:N){
d <- filter(data, participantID==p, day.response %in% 51:100)
for ( v in seq_along(emaLabels)){
log_loops$completed_T2[(p-1)*length(emaLabels)+v] <- sum(!is.na(d [ ,5+v]))/50 # proportion completed
}
# Chunk 6: Kalman
#   apply Kalman filter to impute at level of participant, based on full 100d
data_imputed <- data
library("imputeTS")
for (p in 1:N){
for (v in seq_along(emaLabels)){
if (length(unique(na.omit(data[data_imputed$participantID == p, 5+v]))) > 1){
data_imputed[data_imputed$participantID == p, 5+v] <- na_kalman(data[data_imputed$participantID == p, 5+v]) # throws error, see Note below
cat("<- T ","ID",p,"var",v, sep = "")         # for check
} else  data_imputed[data_imputed$participantID == p, 5+v] <- unique(na.omit(data[data_imputed$participantID == p, 5+v]))
cat("<- F","ID",p,"var",v, sep = "")          # for check
}
# glimpse(data_imputed)
# glimpse(data)
data <- data_imputed
# NOTE:
# error is thrown when assigning imputed data to df:
#
# possible convergence problem: 'optim' gave code = 52
# and message ‘ERROR: ABNORMAL_TERMINATION_IN_LNSRCH’            [,1]      [,2]
#
# I checked the iterations with errors manually, the imputation and assignment seem to work despite error, so I continue.
#
# example of itiration w errors:
# i = 86; v = 41
# cbind( data_imputed[data_imputed$participantID == p, 5+v] , na_kalman(data[data_imputed$participantID == p, 5+v]))
# Chunk 7: detrending
# We detrend at level of participant, using full 100d, and decided to detrend regardless of significance level of linear trend
data_detrended <- data # copy of data to detrend
for (p in 1:N) {
for (v in seq_along(emaLabels)){
formula <- as.formula(paste0(emaLabels[v], " ~ 1 + day.response")) # define formula for linear trend
trend_v <- lm(formula, data = data[data$participantID == p, ]) # fit model per person per var
data_detrended[data_detrended$participantID == p, 5+v] <- residuals(trend_v) # save detrended var
}
}; rm(p, v, formula, trend_v)
data <- data_detrended
# NOTE:
# we for now decided to detrend irregardless of significance of linear effect. # To check for significance of alpha, include below code in loop:
# alpha         <- 0.05 # define alpha for linear trends
# check alpha level and change if not sign ()
# if (anova(trend_v)[["Pr(>F)"]][1] < alpha) {
# } else ...
# Chunk 8: varSelection2
# (1-Normality) t1,
log_loops$norm_T1 <- numeric( N * length(emaLabels) )
for (p in 1:N){
d <- filter(data, participantID==p, day.response %in% 1:50)
for (v in seq_along(emaLabels)){
if (length(unique(na.omit(d[ ,5+v]))) > 1) {
log_loops$norm_T1[(p-1)*length(emaLabels)+v] <- 1-shapiro.test(d[ ,5+v])[[1]]
} else
log_loops$norm_T1[(p-1)*length(emaLabels)+v] <- 0
#      print(c(p, v))
}
# (1-Normality) t2
log_loops$norm_T2 <- numeric( N * length(emaLabels) )
for (p in 1:N){
d <- filter(data, participantID==p, day.response %in% 51:100)
for (v in seq_along(emaLabels)){
if (length(unique(na.omit(d[ ,5+v]))) > 1) {
log_loops$norm_T2[(p-1)*length(emaLabels)+v] <- 1-shapiro.test(d[ ,5+v])[[1]]
} else
log_loops$norm_T2[(p-1)*length(emaLabels)+v] <- 0
#      print(c(p, v))
}
# rank stat
log_loops$rank_stat <- log_loops$completed_T1 * log_loops$completed_T2 * log_loops$norm_T1 * log_loops$norm_T2
# peak at rank statistics:
# log_loops %>% group_by(emaLabels) %>% summarise( avg = mean(rank_stat)) %>% View()
# Chunk 9: Composites
# compute composite variables for positive affect, negative affect, and stress severity
data$PosAffect_sum <- data$alert + data$active + data$attentive + data$determined + data$inspired
data$NegAffect_sum <- data$afraid + data$nervous + data$hostile + data$ashamed + data$upset
data$StressSev_sum <- data$severe1 + data$severe2 + data$severe3 + data$severe4 + data$severe5 + data$severe6 + data$severe7
# TODO: should I use avearge scores instead? more common I guess
data$PosAffect_avg <- rowMeans( cbind(
data$alert, data$active, data$attentive, data$determined,  data$inspired ))
data$NegAffect_avg <- rowMeans( cbind(
data$afraid, data$nervous, data$hostile, data$ashamed, data$upset ))
data$StressSev_avg <- rowMeans( cbind(
data$severe1, data$severe2, data$severe3, data$severe4, data$severe5, data$severe6, data$severe7 ))
# TODO: reverse code positive affect for better visual interpretability?
# Chunk 10: NetworkEstimation
# empty data frame for network output
networks <- data.frame(
ID = rep(1:N, each = 2),
Wave = rep(c("T1", "T2"), N),
PCC_PA_NA = NA,
PCC_PA_Stress = NA,
PCC_PA_Task = NA,
PCC_PA_Rank1 = NA,
PCC_PA_Rank2 = NA,
PCC_NA_Stress = NA,
PCC_NA_tasks = NA,
PCC_NA_Rank1 = NA,
PCC_NA_Rank2 = NA,
PCC_Stress_tasks = NA,
PCC_Stress_Rank1 = NA,
PCC_Stress_Ranks2 = NA,
PCC_Tasks_Rank1 = NA,
PCC_Tasks_Rank2 = NA,
PCC_Rank1_Rank2 = NA,
PDC_PA_PA = NA,
PDC_PA_NA = NA,
PDC_PA_Stress = NA,
PDC_PA_Tasks = NA,
PDC_PA_Rank1 = NA,
PDC_PA_Rank2 = NA,
PDC_NA_PA = NA,
PDC_NA_NA = NA,
PDC_NA_Stress = NA,
PDC_NA_Tasks = NA,
PDC_NA_Rank1 = NA,
PDC_NA_Rank2 = NA,
PDC_Stress_PA = NA,
PDC_Stress_NA = NA,
PDC_Stress_Stress = NA,
PDC_Stress_Tasks = NA,
PDC_Stress_Rank1 = NA,
PDC_Stress_Rank2 = NA,
PDC_Tasks_PA = NA,
PDC_Tasks_NA = NA,
PDC_Tasks_Stress = NA,
PDC_Tasks_Tasks = NA,
PDC_Tasks_Rank1 = NA,
PDC_Tasks_Rank2 = NA,
PDC_Rank1_PA = NA,
PDC_Rank1_NA = NA,
PDC_Rank1_Stress = NA,
PDC_Rank1_Tasks = NA,
PDC_Rank1_Rank1 = NA,
PDC_Rank1_Rank2   = NA,
PDC_Rank2_PA = NA,
PDC_Rank2_NA = NA,
PDC_Rank2_Stress = NA,
PDC_Rank2_Tasks = NA,
PDC_Rank2_Rank1 = NA,
PDC_Rank2_Rank2 = NA,
PDC_by_col  = NA,
SumImputed = NA,# sum of imputed data points in T1 netw
Rank1Var = NA, # selected 5th variable included in netw
Rank2Var = NA, # selected 6th variable included in netw
converged = NA, # FALSE = model did not converge
empty = NA , # TRUE = estimated model is emmpty
EBIC = NA,
gamma = NA
)
# BeckJohnson2020 use gamma = 0, Lambda 0.025:0.25
for (p in 1:N){
# filter data by participant
d_T1 <- filter(data, participantID==p, day.response %in% 1:50)
d_T2 <- filter(data, participantID==p, day.response %in% 51:100)
#  extract two highest ranking DPDS variables, higher rank stat = better
dpds  <- filter(log_loops,
log_loops$ID == p,
log_loops$emaLabels %in%
grep("dpds", log_loops$emaLabels, value = TRUE)
)
dpds_ranked <- dpds[order(dpds$rank_stat, decreasing = TRUE), ]
Rank1       <- dpds_ranked[1, 3]
Rank2       <- dpds_ranked[2, 3]
# select variables for individualized network
d_T1 <- select(d_T1,
day.response,
PosAffect_sum,
NegAffect_sum,
StressSev_sum,
tasks,
Rank1,
Rank2
)
d_T2 <- select(d_T2,
day.response,
PosAffect_sum,
NegAffect_sum,
StressSev_sum,
tasks,
Rank1,
Rank2
)
# BeckJohnson2020 used gamma = 0, Lambda 0.025:0.25
netw_T1 <- graphicalVAR(d_T1,
beepvar = "day.response",
gamma = 0,
lambda_beta = seq(.025, 1, .025)
)
cat("<- netwT1 ", p)
netw_T2 <- graphicalVAR(d_T2,
beepvar = "day.response",
gamma = 0,
lambda_beta = seq(.025, 1, .025)
)
cat("<- netwT2", p)
networks[networks$ID == p, 3:17] <-
rbind(as.vector(netw_T1$PCC[lower.tri(netw_T1$PCC)]),
as.vector(netw_T2$PCC[lower.tri(netw_T2$PCC)])
)
networks[networks$ID == p, 18:53] <-
rbind(as.vector(netw_T1$PDC),
as.vector(netw_T2$PDC)
)
}
####################
# extract metrics per network
# density
# proportion empty edges
# comparisons
# correlation adj matr PCC
# correlation adj matr PDC
#
# prop of edges that are estimated as empty, positive or negative in both networks =
# jacqard similarity: (count of agreeing categories)/ (count of all edges)
#
####################
# save network objects (for later), here("data",)
# assign(paste0("ID",p,"_T1"), netw_T1) #4.4mb per netw
# save RDS in subfolder using here()
# TODO build in option for empty networks and non-converging networks
# kappa matrix  is partial contemp corr PCC
# beta matrix is partical directed correlations PDC
#
# compute comparison metric, see Mansueto code for examples
# vechs(cont) for contemp netw
# TODO plot networks
# Names for the Plot :
names <- c("PA", "NA", "Stress", "Tasks", toupper(Rank1), toupper(Rank2) )
# for plots, fix layout and node strength for comparability
# qgraph(netw_T1$PCC,  layout = "circle", nonsig = "hide", theme = "colorblind", title = "Contemporaneous", labels = names, vsize = 10,  asize = 10, mar = c(5,5,5,5))
View(idx_missing)
View(networks)
return(netw_T1)
# PPC:3:17, PDC 18:53
networks$pr_empty_PCC <- networks$
networks$pr_empty_PDC <-
networks[1 ,3:17]
# PPC:3:17, PDC 18:53
networks$pr_empty_PCC <- networks$
networks$pr_empty_PDC <-
networks[1 ,3:17]
# PPC:3:17, PDC 18:53
networks$pr_empty_PCC <- networks$
networks$pr_empty_PDC <-
networks[1 ,3:17]
str(networks)
dim(networks)
# PPC:3:17, PDC 18:53
networks$pr_empty_PCC <- networks$
networks$pr_empty_PDC <-
networks[[1 ,3:17]]
View(networks)
str(networks)
networks[1,1]
networks[1,1:2]
networks[ ,3:17]
networks[ ,3:17] == 0
sum(networks[ ,3:17] == 0)
# PPC:3:17, PDC 18:53
networks$pr_empty_PCC <- networks$
networks$pr_empty_PDC <- rowSum(networks[ ,3:17] == 0)
rowsum(networks[ ,3:17] == 0)
rowmeans(networks[ ,3:17] == 0)
rowMeans(networks[ ,3:17] == 0)
# PPC:3:17, PDC 18:53
networks$pr_empty_PCC <- networks$
networks$pr_empty_PDC <- rowMeans(networks[ ,3:17] == 0)
# PPC:3:17, PDC 18:53
networks$pr_empty_PCC <- networks$
networks$pr_empty_PDC <- rowMeans(networks[ ,3:17] == 0)
networks[ ,3:17] == 0
rowMeans(networks[ ,3:17] == 0)
networks$pr_empty_PDC <-
rowMeans(networks[ ,3:17] == 0) %>% str()
networks$pr_empty_PCC <- rowMeans(networks[ ,3:17] == 0)
networks$pr_empty_PDC <- rowMeans(networks[ ,18:53] == 0)
sum(networks$pr_empty_PCC == 1)
sum(networks$pr_empty_PDC == 1)
p = 1
cor(networks[(p-1)*2 + p, 3:17], networks[(p-1)*2 + p+1 , 3:17])
networks[(p-1)*2 + p, 3:17]
networks[(p-1)*2 + p+1 , 3:17]
networks[(p-1)*2 + p, 3:17] %>% as.numeric()
cor(networks[(p-1)*2 + p, 3:17] %>% as.numeric(),
networks[(p-1)*2 + p+1 , 3:17])  %>% as.numeric()
cor(as.numeric(networks[(p-1)*2 + p, 3:17]),
as.numeric(networks[(p-1)*2 + p+1 , 3:17])
)
cor_PCCs <- numeric(N)
comparisons <- data.frame(
ID = 1:N,
PCCs_cor_ = NA,
PCCs_Jaccard = NA,
PDCs_cor = NA,
PDCs_Jaccard = NA
)
comparisons <- data.frame(
ID = 1:N,
PCCs_cor = NA,
PCCs_Jaccard = NA,
PDCs_cor = NA,
PDCs_Jaccard = NA
)
for (p in 1:N) {
comparisons$PCCs_cor <- cor(as.numeric(networks[(p-1)*2 + p, 3:17]),
as.numeric(networks[(p-1)*2 + p+1 , 3:17])
)
# comparisons$PCCs_Jaccard <-
comparisons$PDCs_cor <- cor(as.numeric(networks[(p-1)*2 + p, 18:53]),
as.numeric(networks[(p-1)*2 + p+1 , 18:53])
)
# comparisons$PDCs_Jaccard <-
}
warnings()
cor( c(0,0,0), c(1,2,3))
cor( c(1,0,0), c(1,2,3))
cor( c(1,2,3), c(1,2,3))
cor( c(1,0,3), c(1,2,3))
cor( c(-1,-2,-3), c(1,2,3))
cor( c(-3,-2,-1), c(1,2,3))
cor( c(0,3,5), c(1,2,3))
View(comparisons)
comparisons <- data.frame(
ID = 1:N,
PCCs_cor = NA,
PCCs_Jaccard = NA,
PDCs_cor = NA,
PDCs_Jaccard = NA
)
for (p in 1:N) {
comparisons$PCCs_cor <- cor(as.numeric(networks[(p-1)*2 + p, 3:17]),
as.numeric(networks[(p-1)*2 + p+1 , 3:17])
)
# comparisons$PCCs_Jaccard <-
comparisons$PDCs_cor <- cor(as.numeric(networks[(p-1)*2 + p, 18:53]),
as.numeric(networks[(p-1)*2 + p+1 , 18:53])
)
# comparisons$PDCs_Jaccard <-
}
cor(as.numeric(networks[(p-1)*2 + p, 3:17]),
as.numeric(networks[(p-1)*2 + p+1 , 3:17])
)
as.numeric(networks[(p-1)*2 + p, 3:17])
networks[(p-1)*2 + p, 3:17]
cor(as.numeric(networks[(p-1)*2 + p, 3:17])
networks[(p-1)*2 + p, 3:17]
p=1
networks[((p-1)*2 + p), 3:17]
networks[(p-1)*2 + p+1 , 3:17]
cor(as.numeric(networks[(p-1)*2+p , 3:17]),
as.numeric(networks[(p-1)*2+p+1 , 3:17])
)
cor(as.numeric(networks[(p-1)*2 + p, 18:53]),
as.numeric(networks[(p-1)*2 + p+1 , 18:53])
)
for (p in 1:N) {
comparisons$PCCs_cor <- cor(as.numeric(networks[(p-1)*2+p , 3:17]),
as.numeric(networks[(p-1)*2+p+1 , 3:17])
)
# comparisons$PCCs_Jaccard <-
comparisons$PDCs_cor <- cor(as.numeric(networks[(p-1)*2 + p, 18:53]),
as.numeric(networks[(p-1)*2 + p+1 , 18:53])
)
# comparisons$PDCs_Jaccard <-
}
comparisons <- data.frame(
ID = 1:N,
PCCs_cor = NA,
PCCs_Jaccard = NA,
PDCs_cor = NA,
PDCs_Jaccard = NA
)
for (p in 1:N) {
comparisons$PCCs_cor[p] <- cor(as.numeric(networks[(p-1)*2+p , 3:17]),
as.numeric(networks[(p-1)*2+p+1 , 3:17])
)  # comparisons$PCCs_Jaccard <-
comparisons$PDCs_cor[p] <- cor(as.numeric(networks[(p-1)*2 + p, 18:53]),
as.numeric(networks[(p-1)*2 + p+1 , 18:53])
)
}
hist(comparisons$PCCs_cor)
hist(comparisons$PDCs_cor)
hist(comparisons$PCCs_cor, breaks = 79)
hist(comparisons$PDCs_cor, breaks = 79)
for (p in 1:N) {
comparisons$PCCs_cor[p] <- cor(as.numeric(networks[(p-1)*2+p , 3:17]),
as.numeric(networks[(p-1)*2+p+1 , 3:17])
, method = "Spearman")  # comparisons$PCCs_Jaccard <-
comparisons$PDCs_cor[p] <- cor(as.numeric(networks[(p-1)*2 + p, 18:53]),
as.numeric(networks[(p-1)*2 + p+1 , 18:53])
, method = "Spearman")
}
hist(comparisons$PCCs_cor, breaks = 79)
hist(comparisons$PDCs_cor, breaks = 79)
for (p in 1:N) {
comparisons$PCCs_cor[p] <- cor(as.numeric(networks[(p-1)*2+p , 3:17]),
as.numeric(networks[(p-1)*2+p+1 , 3:17])
, method = "spearman")  # comparisons$PCCs_Jaccard <-
comparisons$PDCs_cor[p] <- cor(as.numeric(networks[(p-1)*2 + p, 18:53]),
as.numeric(networks[(p-1)*2 + p+1 , 18:53])
, method = "spearman")
}
hist(comparisons$PCCs_cor, breaks = 79)
hist(comparisons$PDCs_cor, breaks = 79)
library(papaja)
install.packages("papaja")
r
R
.libPaths()
