# rename participant IDs Baseline with same pipeline used for daily data
#------------------------------------------------------------------------
data <- read.csv(here("data", "dd100_baseline.csv")) %>% select(-X)
# exclude participants
data <- filter(data, participantID %in% idx_included$ID)
# rename IDs for easy looping
data$participantID <- factor(data$participantID,
levels = unique(data$participantID),
labels = 1:length(unique(data$participantID))) %>%
as.numeric()
# N: nr participants retained
N1 <- length(unique(data$participantID))
data_baseline <- data; rm(data)
saveRDS(data_baseline, file = here("data", "data_baseline.RDS"))
saveRDS(data_daily_raw, file = here("data", "data_daily_raw.RDS"))
# Chunk 4: Kalman
data      <- data_daily_raw
emaLabels <- data %>%
select(tasks:dpds32) %>%
colnames()
#   apply Kalman filter to impute at level of participant, based on full 100d
library("imputeTS")
for (p in 1:N){
for (v in seq_along(emaLabels)){
if (length(unique(na.omit(data[data$participantID == p, 5+v]))) > 1){
data[data$participantID == p, 5+v] <-
na_kalman(data[data$participantID == p, 5+v]) # throws error, see Note below
} else  data[data$participantID == p, 5+v] <-
unique(na.omit(data[data$participantID == p, 5+v]))
}
# compute composite variables for positive affect, negative affect, and stress severity
data$PosAffect <- (data$alert + data$active + data$attentive +
data$determined + data$inspired) / 5
data$NegAffect <- (data$afraid + data$nervous + data$hostile +
data$ashamed + data$upset) / 5
data$StressSev <- (data$severe1 + data$severe2 + data$severe3 +
data$severe4 + data$severe5 + data$severe6 + data$severe7) / 7
emaLabels <-  data %>%
select(-(participantID:total.days)) %>%
colnames()
data_daily_imputed <- data # keep copy of imputed data
saveRDS(data_daily_imputed, file = here("data", "data_daily_imputed.RDS"))
# NOTE:
# error is thrown when assigning imputed data to df:
#
# possible convergence problem: 'optim' gave code = 52
# and message ‘ERROR: ABNORMAL_TERMINATION_IN_LNSRCH’            [,1]      [,2]
#
# I checked the iterations with errors manually, the imputation and assignment seem to work despite error, so I continue.
#
# example of itiration w errors:
# i = 86; v = 41
# cbind( data_daily_imputed[data_daily_imputed$participantID == p, 5+v] , na_kalman(data[data_daily_imputed$participantID == p, 5+v]))
# Chunk 5: detrending
# We detrend at level of participant, using full 100d, regardless of significance level of linear trend
data <- data_daily_imputed
for (p in 1:N) {
for (v in seq_along(emaLabels)){
formula <- as.formula(paste0(emaLabels[v], " ~ 1 + day.response")) # define formula for linear trend
trend_v <- lm(formula, data = data[data$participantID == p, ]) # fit model per person per var
data[data$participantID == p, 5+v] <- residuals(trend_v) # detrend
}
data_detrended <- data # keep copy of data after detrending
saveRDS(data_detrended, file = here("Data", "data_detrended.RDS"))
# NOTE:
# To check for significance of alpha, include below code in loop:
# if (anova(trend_v)[["Pr(>F)"]][1] < 0.05) { ... } else next
# Chunk 6: descriptives
# prepare data frame to store variable descriptives per person per time period
EMA_descriptives <- data.frame(
ID = rep(c(1:N), each = length(emaLabels)),
Var = rep(seq_along(emaLabels), N),
emaLabels = rep(c(emaLabels), N)
)
# function to filter rows for T1 and T2 data
.filterData <- function(timeperiod = c("T1", "T2"), dat, p){
if (timeperiod == "T1"){
t <- 1:50
} else if ( timeperiod == "T2"){
t <- 51:100
} else t <- 1:100
return( filter(dat, participantID == p, day.response %in% t) )
}
# extract variable descriptives
for (p in 1:N){
raw_T1        <- .filterData("T1", data_daily_raw, p)
raw_T2        <- .filterData("T2", data_daily_raw, p)
imputed_T1    <- .filterData("T1", data_daily_imputed, p)
imputed_T2    <- .filterData("T2", data_daily_imputed, p)
detrended_T1  <- .filterData("T1", data_detrended, p)
detrended_T2  <- .filterData("T2", data_detrended, p)
for (v in seq_along(emaLabels)){
# dynamic index for EMA_descriptives df
idx <- (p-1)*length(emaLabels)+v
# proportion completed T1 and T2
EMA_descriptives$nr_imputed_T1[idx] <- sum(is.na(raw_T1[ ,5+v]))
EMA_descriptives$nr_imputed_T2[idx] <- sum(is.na(raw_T2[ ,5+v]))
EMA_descriptives$completed_T1[idx]  <- sum(!is.na(raw_T1[ ,5+v]))/50
EMA_descriptives$completed_T2[idx]  <- sum(!is.na(raw_T2[ ,5+v]))/50
# (1-Normality) Raw Variables T1 and T2:
if (length(unique(na.omit(raw_T1[ ,5+v]))) > 1) {
EMA_descriptives$norm_T1[idx] <-
1-shapiro.test(raw_T1[ ,5+v])[[1]]
} else  EMA_descriptives$norm_T1[idx] <- 0
if (length(unique(na.omit(raw_T2[ ,5+v]))) > 1) {
EMA_descriptives$norm_T2[idx] <-
1-shapiro.test(raw_T2[ ,5+v])[[1]]
} else  EMA_descriptives$norm_T2[idx] <- 0
# (1-Normality) Detrended Variables T1 and T2
if (length(unique(na.omit(raw_T1[ ,5+v]))) > 1) {
EMA_descriptives$norm_detrended_T1[idx] <-
1-shapiro.test(detrended_T1[ ,5+v])[[1]]
} else  EMA_descriptives$norm_detrended_T1[idx] <-
0
if (length(unique(na.omit(raw_T2[ ,5+v]))) > 1) {
EMA_descriptives$norm_detrended_T2[idx] <-
1-shapiro.test(detrended_T2[ ,5+v])[[1]]
} else  EMA_descriptives$norm_detrended_T2[idx] <-
0
# Means and SDs for T1 and T2:
EMA_descriptives$mean_raw_T1[idx]     <- raw_T1[ ,5+v]     %>% mean(na.rm = TRUE)
EMA_descriptives$mean_raw_T2[idx]     <- raw_T2[ ,5+v]     %>% mean(na.rm = TRUE)
EMA_descriptives$sd_raw_T1[idx]       <- raw_T1[ ,5+v]     %>% sd(na.rm = TRUE)
EMA_descriptives$sd_raw_T2[idx]       <- raw_T2[ ,5+v]     %>% sd(na.rm = TRUE)
EMA_descriptives$mean_imputed_T1[idx] <- imputed_T1[ ,5+v] %>% mean(na.rm = TRUE)
EMA_descriptives$mean_imputed_T2[idx] <- imputed_T2[ ,5+v] %>% mean(na.rm = TRUE)
EMA_descriptives$sd_imputed_T1[idx]   <- imputed_T1[ ,5+v] %>% sd(na.rm = TRUE)
EMA_descriptives$sd_imputed_T2[idx]   <- imputed_T2[ ,5+v] %>% sd(na.rm = TRUE)
EMA_descriptives$mean_detrended_T1[idx] <- detrended_T1[ ,5+v] %>% mean(na.rm = TRUE)
EMA_descriptives$mean_detrended_T2[idx] <- detrended_T2[ ,5+v] %>% mean(na.rm = TRUE)
EMA_descriptives$sd_detrended_T1[idx]   <- detrended_T1[ ,5+v] %>% sd(na.rm = TRUE)
EMA_descriptives$sd_detrended_T2[idx]   <- detrended_T2[ ,5+v] %>% sd(na.rm = TRUE)
}
# compute rank stat raw data
EMA_descriptives$rank_stat <- EMA_descriptives$completed_T1 *
EMA_descriptives$completed_T2 *
EMA_descriptives$norm_T1 *
EMA_descriptives$norm_T2
# rank stat on detrended data
EMA_descriptives$rank_stat_detrended <- EMA_descriptives$completed_T1 *
EMA_descriptives$completed_T2 *
EMA_descriptives$norm_detrended_T1 *
EMA_descriptives$norm_detrended_T2
cor(EMA_descriptives$rank_stat, EMA_descriptives$rank_stat_detrended) # .96, so shouldn't make a difference
saveRDS(EMA_descriptives, file = here("Data", "EMA_descriptives.RDS"))
# to peak at average rank score averages in sample:
# EMA_descriptives %>% group_by(emaLabels) %>% summarise( avg = mean(rank_stat_detrended)) %>% View()
# NOTE
# v = 1: first EMA Variable; located at 6th column in data (thus 5+v)
# ShapiroWilk test stat: 0 = perfect normality, 1 = deviation from normality.
# Because we want to prioritize more normally distributed variables, we use 1-ShapiroWilk.
# As result, a higher rank statistic means better properties.
# Chunk 7: NetworkEstimation
# empty data frame to store path estimates in long format (two rows per participant, 1 for T1, 1 for T2)
networks <- data.frame("ID" = rep(1:N, each=2),
"timeperiod" = rep(c("T1", "T2"), N),
# 3:17 Contemporaneous network: lower triangle in col by col format
"PCC_PA_NA" = NA,
"PCC_PA_Stress" = NA,
"PCC_PA_Task" = NA,
"PCC_PA_Rank1" = NA,
"PCC_PA_Rank2" = NA,
"PCC_NA_Stress" = NA,
"PCC_NA_tasks" = NA,
"PCC_NA_Rank1" = NA,
"PCC_NA_Rank2" = NA,
"PCC_Stress_tasks" = NA,
"PCC_Stress_Rank1" = NA,
"PCC_Stress_Ranks2" = NA,
"PCC_Tasks_Rank1" = NA,
"PCC_Tasks_Rank2" = NA,
"PCC_Rank1_Rank2" = NA,
# 18:53 Temporal networks: full matrix in col by col format
"PDC_PA_PA" = NA,
"PDC_PA_NA" = NA,
"PDC_PA_Stress" = NA,
"PDC_PA_Tasks" = NA,
"PDC_PA_Rank1" = NA,
"PDC_PA_Rank2" = NA,
"PDC_NA_PA" = NA,
"PDC_NA_NA" = NA,
"PDC_NA_Stress" = NA,
"PDC_NA_Tasks" = NA,
"PDC_NA_Rank1" = NA,
"PDC_NA_Rank2" = NA,
"PDC_Stress_PA" = NA,
"PDC_Stress_NA" = NA,
"PDC_Stress_Stress" = NA,
"PDC_Stress_Tasks" = NA,
"PDC_Stress_Rank1" = NA,
"PDC_Stress_Rank2" = NA,
"PDC_Tasks_PA" = NA,
"PDC_Tasks_NA" = NA,
"PDC_Tasks_Stress" = NA,
"PDC_Tasks_Tasks" = NA,
"PDC_Tasks_Rank1" = NA,
"PDC_Tasks_Rank2" = NA,
"PDC_Rank1_PA" = NA,
"PDC_Rank1_NA" = NA,
"PDC_Rank1_Stress" = NA,
"PDC_Rank1_Tasks" = NA,
"PDC_Rank1_Rank1" = NA,
"PDC_Rank1_Rank2"   = NA,
"PDC_Rank2_PA" = NA,
"PDC_Rank2_NA" = NA,
"PDC_Rank2_Stress" = NA,
"PDC_Rank2_Tasks" = NA,
"PDC_Rank2_Rank1" = NA,
"PDC_Rank2_Rank2" = NA,
# 54
"BIC" = NA
)
# index columns for contemporaneous network (PPC: 3:17) and temporal networks (PDC 18:53) in Networks df
idx_PCC <- 3:17
idx_PDC <- 18:53
# data frame for main outcome statistics
comparisons <- data.frame(participantID = 1:N)
# fit networks.
# Specification a la BeckJackson2020, gamma = 0, Lambda range 0.025 to 1
for (p in 1:N){
# if( p %in% c(4)) { next }
# filter data by participant
d_T1 <- filter(data, participantID==p, day.response %in% 1:50)
d_T2 <- filter(data, participantID==p, day.response %in% 51:100)
#  select two highest ranking DPDS/behavior variables, higher rank stat = better
selectVar  <- filter(EMA_descriptives,
EMA_descriptives$ID == p,
EMA_descriptives$emaLabels %in%
emaLabels[c(11:23, 31:60)]
)
selectVar <- selectVar[order(selectVar$rank_stat_detrended, decreasing = TRUE), ]
Rank1       <- selectVar[1, 3]
Rank2       <- selectVar[2, 3]
# log name of DPDS Variables
comparisons$Rank1[p] <- Rank1
comparisons$Rank2[p] <- Rank2
# log total nr imputed data points
comparisons$nr_imputed[p] <- filter(data_daily_raw, participantID==p, day.response %in% 1:100) %>%
select(PosAffect, NegAffect, StressSev, tasks, all_of(Rank1), all_of(Rank2)) %>%
is.na() %>%
sum()
# define individualized networks
d_T1 <- select(d_T1,
day.response,
PosAffect,
NegAffect,
StressSev,
tasks,
all_of(Rank1),
all_of(Rank2)
)
d_T2 <- select(d_T2,
day.response,
PosAffect,
NegAffect,
StressSev,
tasks,
all_of(Rank1),
all_of(Rank2)
)
# BeckJohnson2020 used gamma = 0, Lambda 0.025:1 by 0.025
netw_T1 <- graphicalVAR(d_T1,
beepvar = "day.response",
gamma = 0,
lambda_beta = seq(.025, 1, .0125)
)
cat(paste("T1 participant",p ,"converged"))
netw_T2 <- graphicalVAR(d_T2,
beepvar = "day.response",
gamma = 0,
lambda_beta = seq(.025, 1, .0125)
)
cat(paste("T2 participant",p ,"converged"))
# store full network objects in global environment for later inspection
assign(paste0("ID",p,"_T1"), netw_T1)
assign(paste0("ID",p,"_T2"), netw_T2)
# save network objects for detailed inspection / plotting
saveRDS(netw_T1, here("data", "network_objects", paste0("ID",p,"_T1.RDS")))
saveRDS(netw_T2, here("data", "network_objects", paste0("ID",p,"_T2.RDS")))
# extract path estimates for easy comparison
networks[networks$ID == p, idx_PCC] <-
rbind(netw_T1$PCC[lower.tri(netw_T1$PCC)] %>%
as.numeric()%>%
as.vector() %>%
round(digits=4),
netw_T2$PCC[lower.tri(netw_T2$PCC)] %>%
as.numeric()%>%
as.vector() %>%
round(digits=4)
)
networks[networks$ID == p, idx_PDC] <-
rbind(netw_T1$PDC %>%
as.numeric()%>%
as.vector()%>%
round(digits = 4),
netw_T2$PDC %>%
as.numeric()%>%
as.vector()%>%
round(digits = 4)
)
networks$BIC[networks$ID == p] <- rbind( netw_T1$EBIC, netw_T2$EBIC)
}
# Network descriptives:
## empty edges
networks$nr_zero_PCC        <- rowSums(networks[ ,idx_PCC] == 0)
networks$nr_zero_PDC        <- rowSums(networks[ ,idx_PDC] == 0)
## proportion of empty edges
networks$pr_zero_PCC        <- rowMeans(networks[ ,idx_PCC] == 0) * 100 %>% as.numeric() %>%round( digits = 2)
networks$pr_zero_PDC        <- rowMeans(networks[ ,idx_PDC] == 0) * 100 %>% as.numeric() %>%round( digits = 2)
## estimated edges total
networks$nr_estimated_PCC   <- rowSums(networks[ ,idx_PCC] != 0)
networks$nr_estimated_PDC   <- rowSums(networks[ ,idx_PDC] != 0)
## estimated positive edges
networks$nr_pos_PCC         <- rowSums(networks[ ,idx_PCC] > 0)
networks$nr_pos_PDC         <- rowSums(networks[ ,idx_PDC] > 0)
## estimated positive edges
networks$nr_neg_PCC         <- rowSums(networks[ ,idx_PCC] < 0)
networks$nr_neg_PDC         <- rowSums(networks[ ,idx_PDC] < 0)
## "Connectivity (% possible edges)" a la EpskampEA False Alarm paper
networks$connectivity_PCC   <- round( networks$nr_estimated_PCC /length(idx_PCC) * 100, 2)
networks$connectivity_PDC   <- round( networks$nr_estimated_PDC /length(idx_PDC) * 100, 2)
NrEmptyPCC <- sum(networks$pr_zero_PCC == 100) # 1 empty contemp net total
NrEmptyPDC <- sum(networks$pr_zero_PDC == 100) # 46 empty temp net total
# Compute networks comparison statistics
for (p in 1:N) {
# dynamic index for T1 and T2 rows per person in 'networks' data frame
idx_p_T1  <- (p-1)*2+1
idx_p_T2  <- (p-1)*2+2
PCC_T1    <- networks[idx_p_T1, idx_PCC] %>% as.numeric()
PCC_T2    <- networks[idx_p_T2, idx_PCC] %>% as.numeric()
PDC_T1    <- networks[idx_p_T1, idx_PDC] %>% as.numeric()
PDC_T2    <- networks[idx_p_T2, idx_PDC] %>% as.numeric()
# correlation of all edge weights
comparisons$PCCs_cor[p] <- cor(PCC_T1, PCC_T2, method = "spearman")
comparisons$PDCs_cor[p] <- cor(PDC_T1, PDC_T2, method = "spearman")
# Correlation non-zero edge weights
comparisons$PCCs_cor_non0[p] - cor(PCC_T1[PCC_T1!=0&PCC_T2!=0],PCC_T2[PCC_T1!=0&PCC_T2!=0], method = "spearman")
comparisons$PDCs_cor_non0[p] - cor(PDC_T1[PDC_T1!=0&PDC_T2!=0],PCC_T2[PDC_T1!=0&PDC_T2!=0], method = "spearman")
# Jaccard similarity, https://en.wikipedia.org/wiki/Jaccard_index#Similarity_of_asymmetric_binary_attribute
# proportion of shared non-zero edges relative to number of edges which are non-zero in either, but not both, networks
comparisons$PCCs_Jaccard[p] <-   sum(PCC_T1!=0 & PCC_T2!=0) / sum(PCC_T1!=0 | PCC_T2!=0)
comparisons$PDCs_Jaccard[p] <-   sum(PDC_T1!=0 & PDC_T2!=0) / sum(PDC_T1!=0 | PDC_T2!=0)
# proportion empty edges both netw
comparisons$PCCs_prop_empty[p]     <- mean( PCC_T1 == 0 & PCC_T2 == 0)
comparisons$PDCs_prop_empty[p]     <- mean( PDC_T1 == 0 & PDC_T2 == 0)
# proportion of edges with equal sign or both zero in network
comparisons$PCCs_prop_equ_sign[p]  <- mean( (PCC_T1 == 0 & PCC_T2 == 0) |
(PCC_T1 > 0 & PCC_T2 > 0) |
(PCC_T1 < 0 & PCC_T2 < 0))
comparisons$PDCs_prop_equ_sign[p]  <- mean( (PDC_T1 == 0 & PDC_T2 == 0) |
(PDC_T1 > 0 & PDC_T2 > 0) |
(PDC_T1 < 0 & PDC_T2 < 0))
# proportion of edges with equal sign, excluding zeros
comparisons$PCCs_prop_equ_sign_non0[p]  <- mean((PCC_T1 > 0 & PCC_T2 > 0) |
(PCC_T1 < 0 & PCC_T2 < 0))
comparisons$PDCs_prop_equ_sign_non0[p]  <- mean((PDC_T1 > 0 & PDC_T2 > 0) |
(PDC_T1 < 0 & PDC_T2 < 0))
# BIC avg across T1 and T2
comparisons$avg_BIC[p] <- networks[networks$ID==p, 54] %>% mean()
}
saveRDS(networks, here("data", "networks.RDS"))
saveRDS(comparisons, here("data", "comparisons.RDS"))
# check sascha False Alarm code https://osf.io/xh87b/
# check sForbes Quantifying code https://osf.io/qcrjk/
# Chunk 8: antecendents
networks    <- readRDS(here("data", "networks.RDS"))
comparisons <- readRDS(here("data", "comparisons.RDS"))
formula <- as.formula(paste0(emaLabels[v], " ~ 1 + day.response")) # define formula for linear trend
trend_v <- lm(formula, data = data[data$participantID == p, ]) #
data_merged <- inner_join(data_baseline, comparisons, by = "participantID")
predictors  <- "~ 1 + gender + age + recentTreatment + happy + swlsMean + neoN + neoE + neoO + neoA + neoC + nr_imputed + avg_BIC + PCCs_prop_empty"
fit.Cor         <- lm(formula = as.formula(paste0("PCCs_cor", predictors)), data = data_merged) %>% lm.beta()
fit.CorNon0     <- lm(formula = as.formula(paste0("PCCs_cor_non0", predictors)), data = data_merged) %>% lm.beta()
fit.Jacc        <- lm(formula = as.formula(paste0("PCCs_Jaccard", predictors)), data = data_merged) %>% lm.beta()
fit.EquSign     <- lm(formula = as.formula(paste0("PCCs_prop_equ_sign", predictors)), data = data_merged) %>% lm.beta()
fit.EquSignNon0 <- lm(formula = as.formula(paste0("PCCs_prop_equ_sign_non0", predictors)), data = data_merged) %>% lm.beta()
summary(fit.Cor) # swl + neoc
summary(fit.CorNon0)
summary(fit.Jacc) # neoc
summary(fit.EquSign) # neoc + propempty (duh
summary(fit.EquSignNon0)
# Chunk 9: examplePx
# choose 2 participants with high vs low PCC cor, but similar density
data_merged %>%
filter(
PCCs_prop_empty < 0.55,
nr_imputed < 5
) %>% arrange (PCCs_cor)
# 53 low 0.1823801 low  dpds25 dpds21 a
# 45 high 0.6480437,passive dpds24
# ebics most similar in t1 and t2
# Define equal max edge weight fpr plots Px 53 and 45
maxEdge <- networks %>% filter( ID %in% c(53, 45)) %>%
select(idx_PCC)  %>% abs() %>% max()
ID53_T1 <- readRDS(here("data", "network_objects", "ID53_T1.RDS"))
ID53_T2 <- readRDS(here("data", "network_objects", "ID53_T2.RDS"))
ID45_T1 <- readRDS(here("data", "network_objects", "ID45_T1.RDS"))
ID45_T2 <- readRDS(here("data", "network_objects", "ID45_T2.RDS"))
# Chunk 10: plotPx53Netws
# set par to 2 * 2
# DPDS25: I acted on impulse while feeling upset.
# DPDS21: I worried about being abandoned.
# qgraph arguments
names <- c("PA", "NA", "Stress", "Task", "Impuls", "Worry")
# 53 low 0.1823801 low  dpds25 dpds21 a
Px53_T1 <- ID53_T1$PCC %>%
qgraph(maximum = maxEdge,
details = TRUE,
theme="colorblind",
title = "Days 1 to 50",
negDashed = TRUE,
labels = names,
nodeNames =c("Positive Affect", "Negative Affect", "Stress", "Impairment daily tasks", "Impulsive while upset", "Worry about abandonment")
)
Px53_T2 <- ID53_T2$PCC %>%
qgraph(maximum = maxEdge,
details = TRUE,
theme="colorblind",
title = "Days 51 to 100",
negDashed = TRUE,
labels = names,
nodeNames =c("Positive Affect", "Negative Affect", "Stress", "Impairment daily tasks", "Impulsive while upset", "Worry about abandonment")
)
# for plots, fix layout and node strength for comparability
# qgraph(netw_T1$PCC,  layout = "circle", nonsig = "hide", theme = "colorblind", title = "Contemporaneous", labels = names, vsize = 10,  asize = 10, mar = c(5,5,5,5))
# Chunk 11: plotPx53Descr
# DPDS25: I acted on impulse while feeling upset.
# DPDS21: I worried about being abandoned.
# Behavior and DPD vars are on 0:7 already
dataPX53 <- data_daily_raw %>%
filter( participantID==53, day.response %in% 1:100) %>%
# rescale to range 0-7 for plotting, with 7 reflecting highest score of this participant
mutate(PosAffect_rescaled = PosAffect * 7/max(na.omit(PosAffect)),
NegAffect_rescaled = NegAffect * 7/max(na.omit(NegAffect)),
StressSev_rescaled = StressSev * 7/max(na.omit(StressSev)),
tasks_rescaled     = tasks * 7/max(na.omit(tasks))
) %>%
select(day.response,
PosAffect_rescaled,
NegAffect_rescaled,
StressSev_rescaled,
tasks_rescaled,
dpds25,
dpds21) %>%
rename("Positive Affect" = PosAffect_rescaled,
"Negative Affect" = NegAffect_rescaled,
"Stress" = StressSev_rescaled,
"Impairment daily tasks" = tasks_rescaled,
"Impulsive while upset" = dpds25,
"Worry about abandonment" = dpds21) %>%
melt( id.vars = "day.response") %>%
rename( "Variable" = variable)
dataPX53 %>%  ggplot(
aes(x = day.response, y = value, colour = Variable, group=Variable)
) +
geom_line() +
coord_fixed() +
theme_apa(box = TRUE) +
labs( x = "Day", y = "Rating (scaled)")
# Chunk 12: plotPx45Netws
# 45 high 0.6480437,passive dpds24
names <- c("PA", "NA", "Stress", "Tasks", "Passive", "Unusual")
maxEdge <- networks %>% filter( ID %in% c(53, 45)) %>%
select(idx_PCC)  %>% abs() %>% max()
Px45_T1 <- ID45_T1$PCC %>%
qgraph(maximum = maxEdge,
details = TRUE,
theme="colorblind",
title = "Days 1 to 50",
negDashed = TRUE,
labels = names,
nodeNames =c("Positive Affect", "Negative Affect", "Stress", "Impairment daily tasks", "Passive behavior", "Unusual behavior")
)
Px45_T2 <- ID45_T2$PCC %>%
qgraph(maximum = maxEdge,
details = TRUE,
theme="colorblind",
title = "Days 51 to 100",
negDashed = TRUE,
labels = names,
nodeNames =c("Positive Affect", "Negative Affect", "Stress", "Impairment daily tasks", "Passivity", "Doing unusual things")
)
# Chunk 13: plotPx45Descr
# passive
# dpds24 unusual
comparisons %>% filter( participantID %in% c(45)) %>%
select(Rank1, Rank2)
# Behavior and DPD vars are on 0:7 already
dataPX45 <- data_daily_raw %>%
filter( participantID==45, day.response %in% 1:100) %>%
select(day.response,
PosAffect_rescaled,
NegAffect_rescaled,
StressSev_rescaled,
tasks_rescaled,
passive,
dpds24)  %>%
rename("Positive Affect" = PosAffect_rescaled,
"Negative Affect" = NegAffect_rescaled,
"Stress" = StressSev_rescaled,
"Impairment daily tasks" = tasks_rescaled,
"Passive behavior" = passive,
"Unusual behavior" = dpds24) %>%
melt( id.vars = "day.response") %>%
rename( "Variable" = variable)
dataPX45 %>%  ggplot(
aes(x = day.response, y = value, colour = Variable, group=Variable)
) +
geom_line() +
coord_fixed() +
theme_apa(box = TRUE) +
labs( x = "Day", y = "Rating (scaled)")
