---
title             : "Temporal stability of idiographic psychological networks"
shorttitle        : "Temporal stability of idiographic networks"

author: 
  - name          : "Ricarda K. K. Proppert"
    affiliation   : "1"
    corresponding : yes 
    address       : "Leiden University, The Netherlands"
    email         : "Ricarda.Proppert@gmail.com"

affiliation:
  - id            : "1"
    institution   : "Leiden University, The Netherlands"

abstract: |
  Evidence-based mental health programs have long conceptualized mental disorders in terms of interactions between thoughts, feelings, behaviours and external factors.
  Idiographic network models are a relatively novel way of modeling such intra-individual psychological processes. 
  These methods are not without limitations, and concerns have been raised about the stability and accuracy of estimated networks. 
  The extend to which idiographic networks are stable, or vary over time, is unknown.
  We explored temporal network stability from three angles, exploring variation within people, across different stability metrics, and across people.
  We reanalysed daily symptom records of people with personality disorders. 
  We fit graphical Vector Autoregressive models separately for the first and second 50 days of consecutive measurements. 
  Overall, idiographic networks appeared to be relatively stable within people. The assessment of stability varied considerably across metrics applied. 
  There was large variation in network stability across people, which could not be explained by subject-specific variables.
  We illustrate the temporal changes in network structure in two participants with respectively high and low network stability, and discuss the most pressing questions to be considered by future research.
  
authornote: |
  Thesis project for the Research Master Clinical & Health Psychology, supervised by Eiko Fried, Ph.D., Leiden University. We thank Aidan Wright, Ph.D., Pittsburgh University, for sharing data for this reanalysis. The data and analysis script are available at https://github.com/RicardaP/thesis_repo and https://osf.io/gnw4s.

  
keywords          : "stability, replicability, consistency, idiographic, subject-specific, psychological networks, network comparison"
wordcount         : "000"
note              : "s1348981"

floatsintext      : yes
figurelist        : yes
tablelist         : yes
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no


documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_doc

bibliography: references.bib
editor_options:
  markdown:
    wrap: sentence
    
header-includes:
  - \usepackage{setspace}
  - \captionsetup[figure]{font={stretch=1,scriptsize}}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set( echo = FALSE,
                       results = "asis",
                       warning = FALSE,
                       message = FALSE,
                       eval = TRUE)

# install.packages("here")
# setwd("~/GitHub/thesis_repo")
library("here")
here::i_am("ThesisAnalysisV2.Rmd") # find directory where file is in
# install.packages("conflicted")
library("conflicted")
conflict_prefer("filter", "dplyr")
# install.packages("tidyverse")
library("tidyverse")
# install.packages("papaja")
library("papaja")
# install.packages("imputeTS")
 library("imputeTS")
# install.packages("graphicalVAR")
library("graphicalVAR")
# install.packages("qgraph")
library("qgraph")
# install.packages("reshape2")
library("reshape2")
# install.packages("lm.beta")
library("lm.beta")



data_daily_raw    <- readRDS(here("data", "data_daily_raw.RDS"))  # raw diary data after exclusion
data_baseline <- readRDS(here("data", "data_baseline.RDS")) # baseline data after exclusion

data_daily_imputed  <- readRDS(here("data", "data_daily_imputed.RDS"))
data_detrended      <- readRDS(here("data", "data_detrended.RDS"))
data_merged         <- readRDS(here("data", "data_merged.RDS"))

networks    <- readRDS(here("data", "networks.RDS"))
comparisons <- readRDS(here("data", "comparisons.RDS"))

ID53_T1 <- readRDS(here("data", "network_objects", "ID53_T1.RDS"))
ID53_T2 <- readRDS(here("data", "network_objects", "ID53_T2.RDS"))
ID45_T1 <- readRDS(here("data", "network_objects", "ID45_T1.RDS"))
ID45_T2 <- readRDS(here("data", "network_objects", "ID45_T2.RDS"))

idx_PCC <- 3:17
idx_PDC <- 18:53
emaLabels <-  data_daily_raw %>% 
              select(-(participantID:total.days)) %>% 
              colnames()


# datafolder <- here("Data")
# rds         <- dir(datafolder, pattern = "*.RDS")
#-------------------------------------------------
# r_refs("r-references.bib")

# Notation: 
# ---------
#     data:   placeholder for data used in specific chunk
#     p:      participant (iteration in loop)
#     v:      variable (iteration in loop)
#     d:      temporary data object in loop
#     T1:     days 1 - 50
#     T2:     days 51-100


# sessionInfo()
# -------------
# R version 4.0.3 (2020-10-10)
# Platform: x86_64-apple-darwin17.0 (64-bit)
# Running under: macOS Big Sur 10.16
```

# Introduction

## Idiographic psychological networks

Idiographic network models are of growing interest to clinical psychology because they may address two recently voiced calls in clinical psychology.
First, there seems to be a need for psychological research to re-orient towards idiographic methods that focus on intra-individual processes as opposed to group-level differences [@Molenaar2004].
Second, scholars have been calling for a paradigm shift away from reductionism towards studying the complexity of psychological phenomena.

The Network theory of mental disorders [@BorsboomCramer2013; @CramerEtAl2010] attempts to integrate psychology with insights and methods from complexity science, offering a novel framework for understanding the underpinnings of psychopathology.
It conceptualizes psychopathology as an emergent state of dynamically interacting elements, for example, psychological states, behaviors, or stressors.
These elements are conceptualized as agents, meaning that they are mutually related in causal ways.
Symptoms are thus thought to contribute, not result from, psychopathology.
This account seems closely aligned with established clinical practices, where a patient's psychologcial disorder is visualized as a path diagram.
These informal case conceptualizations describe the proposed mechanisms of a given disorder (@BurgerEtAl2020, @ScholtenEtAl2020).
They often feature dynamics which align with complex system behaviors, such as vicious cycles dysfunctional thoughts and behaviors.
The recent attempts to formalize and study such symptom dynamics using network science thus fell on futile ground.

Psychological network models (@EpskampEtAl2018) are the methodological workhorse that quantify and visualize such system structures and dynamics as nodes connected through pairwise edges.
Nodes typically represent psychological variables, and edges represent their pairwise relationships.
Relationships may be directed (granger-causal) or undirected (correlational), positive or negative, and can differ in strength.
Network models thus come in many different flavors, pertaining to the estimation procedures by which edge parameters are modeled and derived, and lend themselves to a multitude of research questions.
Besides traditional nomothetic approaches, they are suited to study intra-individual processes using N=1 time-series data.
Researchers in clinical psychology hope that such models could resolve what is known as the Therapist's dilemma, by which therapists need to make predictions about their individual patients based on research findings that may not allow such inferences (for recent reviews, see @FrumkinEtAl2020, @HoweEtAl2020, @CavigliaColeman2016, @HoffartJohnson2020).

Summing up, psychological network models have been described as "window into a patient's daily life" @EpskampEtAl2018a.
The question remains whether this window provides an unobstructed and representative view.
Is it merely a doorhole, or panoramic window?
Are we getting a clear view inside, or are we mostly seeing our own reflections?

## Temporal stability of idiographic networks

Concepts of stability and change lie at the heart of much clinical research How does a person change from being healthy to becoming depressed?
Can therapy facilitate positive change beyond the duration of treatment?
And if change occurs, what mechanism does it actually build on?
Psychological networks offer new ways of mapping these questions onto idiographic research designs.
For example, changes in network structure have been related to therapeutic progress [@ThononEtAl2020] or relapse [@WichersEtAl2016].
Even subtle changes in network structure are of interest, as they are thought to act as potential early warning signals which may predict future major change, i.e. a system's phase transition from a healthy attractor state to a disordered one.
For example, signs of critical slowing down, showing as increased auto-correlations and variances of items, may foreshadow a patient's relapse into depression upon stopping antidepressant treatment (@WichersEtAl2016; for similar work on resilience, see @KuranovaEtAl2020).

Such N=1 research is quasi-experimental by nature.
The counterfactual question of "What would have happened otherwise?" cannot be answered as readily as in cross-sectional randomized controlled designs.
The individual remains their own control group, and it is essential to understand how this *control group* may or may not change when no *change* is expected.
To our knowledge, only one study has investigated the temporal stability of idiographic psychological networks in a setting where no profound change was expected.
@BeckJackson2020a investigated the consistency of idiographic personality over the course of two years.
They found that personality networks of contemporaneous associations to be generally stable within individuals.
However, they do considerable interpersonal variability herein, which appeared to be only weakly attributable to participants' life satisfactions but for most part unexplained.

## Aim of this study

The present study aims to assess the stability of idiographic networks in the context of psychopathology from three different angles.
First, we explore the temporal stability of networks within people.
Second, we explore variation in network stability across commonly used stability metrics.

-   RQ1: How stable are estimated idiographic network structures over time?
-   RQ2: Do stability estimates vary across common stability metrics used?
-   RQ3: What person-specific or model-specific factors explain interpersonal variation in idiographic network stability?

We re-analyze daily diary data of people diagnosed with a personality disorder [@WrightEtAl2015a; @WrightSimms; @WrightEtAl2015].
Participants (N=116) provided once-daily ratings of their mood, behavior, and daily stressors over the course of one hundred consecutive days.
To assess intra-individual stability of idiographic networks (RQ1), we fit subject-specific graphical Vector Auto-regressive models (graphical VAR, @EpskampEtAl2018b ) on participants' first and last fifty days of measurement separately.
Network structures of each individual's first (T1) vs. last fifty days (T2) are compared in their global structure on multiple indices.
We examine differences in how metrics conceptualize and detect network stability by visually examining resulting indices in relation to each other (RQ2).
Person-specific and network-specific attributes are explored for their ability to explain interindividual variation in network stability using multivariate linear regression (RQ3).
We illustrate and interpret the temporal network stability of two participants by example and end with a discussion of relevant questions to be addressed by future research.

# Methods

We used R <!--# TODO: cite and migrate refs --> for all our analyses.
Data and analysis scripts are available at github.com/RicardaP/thesis_repo.

## Data Set

### Sample

### Procedure

### Measures

```{r readData, eval = FALSE}
#---------------------------------------------------------
# Processing of original (unpublished) data.
# Please use "dd100_daily.csv" and "dd100_baseline.csv" below.
#---------------------------------------------------------
# read data
# data <- read.csv(here("data", "dd100-proppert.csv"))
# 
# N <- data$participantID %>% unique()
# range(N) # 1 : 116
# length(unique(N)) # 112
# setdiff(1:116, N) # Participants  8, 25, 45, 92  had been excluded by original authors because more than 30% of responses were missing
# 
# # rename IDs for easier looping
# data$participantID <- factor(
#   data$participantID, 
#   levels = unique(data$participantID), 
#   labels = 1:length(unique(data$participantID))
#   ) %>% 
#   as.numeric()
# 
# # select variables I want to use, save to publish along code
# data_daily    <- data %>% select(participantID:dpds32) %>% select(-sleep, -alcohol.daily, -drugs.daily, -starts_with("stress")) # daily
# data_baseline <- data %>% select(participantID, assessment.date:age, happy, swlsMean, recentTreatment, neoN:neoC) %>% distinct()
# write.csv(data_daily, here("data", "dd100_daily.csv"))
# write.csv(data_baseline, here("data", "dd100_baseline.csv"))
# rm(data)

```

+-------------------------------+-----------------------------------------------------------------------------------------------------------------------+
| Name                          | Scale or Item [range]                                                                                                 |
+:==============================+:======================================================================================================================+
| Positive Affect               | Mean (Active, Alert, Attentive, Determined, Inspired)\                                                                |
|                               | [0 = very slightly : 4 = extremely]                                                                                   |
+-------------------------------+-----------------------------------------------------------------------------------------------------------------------+
| Negative Affect               | Mean (Afraid, Nervous, Hostile, Ashamed, Upset)\                                                                      |
|                               | [0 = very slightly : 4 = extremely]                                                                                   |
+-------------------------------+-----------------------------------------------------------------------------------------------------------------------+
| Stress                        | Mean (Stress1 : Stress7)\                                                                                             |
|                               | [0 = not at all : 3 = very]                                                                                           |
+-------------------------------+-----------------------------------------------------------------------------------------------------------------------+
| Task impairment               | "How much difficulty did you have in taking care of important tasks or responsibilities?"\                            |
|                               | [0 = not at all : 7 = extremely]                                                                                      |
+-------------------------------+-----------------------------------------------------------------------------------------------------------------------+
| Behavior (other)              | Dominant, Assertive, Critical, Irritable, Indifferent, Introverted, Passive, Submissive, Trusting, Warm, Sympathetic\ |
|                               | [0 = extremely inaccurate : 5 = extremely accurate]                                                                   |
+-------------------------------+-----------------------------------------------------------------------------------------------------------------------+
| Personality disorder symptoms | Daily Expression of Personality Disorders (DPDS-32)\                                                                  |
|                               | [0 = not at all : 7 = very much]                                                                                      |
+-------------------------------+-----------------------------------------------------------------------------------------------------------------------+

: (\#tab:DailyTab) Daily measures included in network models

Daily variables and respective scales are shown in Table \@ref(tab:DailyTab).

## Network estimation

Networks were estimated using the R package *graphicalVAR* [@EpskampEtAl2018b].
Graphical VAR models belong to a wider family of partial correlation networks.
Edges are modeled as partial correlations between variables using vector autoregression.
Graphical VAR estimates two types of networks: First, a temporal network of lagged effects is derived.
Each variable in the network is modeled as a function of all other variables in the network at the previous lag (in our days, the previous day), including itself.
Edges are thus directed, can be positive or negative, and meet assumptions of granger-causality (REF).
Second, a comtemporaneous network is derived by ..
residual.
<!--# explain more and don't forget to mention regularization and glasso -->

Idiographic network models were estimated separately for T1 and T2, on an individual basis.
Models regularized using BIC by setting the ... gamma to 0.
The tuning parameter lambda, controlling the penalty term applied by gLasso, was set to 0.025.

<!-- Other methods to estimate idiographic network models exist, which each their own benefits. In contrast to multilevel network estimation, which may be preferred for it's ability to estimate individual networks while borrowing infomation from the group-level and requires less data points @EpskampEtAl2018b. However, in multilevel modeling, individual networks are restricted to have the same structure across individuals, which is an unlikely assumption in our heterogeneous sample.-->

## Pre-processing

Data were pre-processed in order to meet assumptions of the graphical VAR model.
In graphical VAR, networks are estimated using vectore autoregression.
As such, in addition to model assumptions pertaining to regression models, it assumes that data are measured at equal distances (lags), and without measurement error.
TODO: participants that were already excluded by Wright We excluded ... participants whose responses were missing on more than 30 days in total, or more than 15 days at either T1 or T2.
To meet the assumption of equal distances between measurement points, remaining missing data were imputed using the Kalman Filter [@Harvey1989]. Kalman imputation has been shown to recover network structures at levels up 50% data missing completely at random [@MansuetoEtAl2020].

Graphical VAR modeling further assumes equal means and variances across time (REF), known as the stationarity assumption.
While many researchers note that this assumption about the process may not be realistic in psychological data, it is generally recommended to transform data to meet this statistical assumption by detrending effects of time.

The effects of data imputation and linear detrending are largely unexplored, but some authors report vastly resulting network structures.
Detrending a variable changes a variables variance and distribution, because detrended scores reflect a variables deviations from it's linear trend over time (the residuals of linear regression model predicting variable scores by time).
Because graphical VAR modeling performs variance-covariance decomposition, changes in vairance may result in lower power and potentially biased path estimates if the assumption of stationarity does not hold.

As examining differences in network structures both withing and between people was the main goal of our study, we tried to equalize pro-processing decisions across variables and participants while working in an idiograhic framework.
Imputation and detrending were performed at the level of the individual across the full 100 days.
Variables were detrended independently of the magnitude and statistical sagnificance of the time effect.

## Variable selection for idiographic networks

The diary data used in this study consists of a broad set of variables assessed in a comparably small and heterogeneous sample.
We selected variables which were most suited for our research question and model requirements.
Variables with high negative skew (e.g. most responses being zero) are generally problematic for model estimation, as they violates the model's assumption of multivariate normality and can lead to model non-convergence.
We further wanted to make the variable selection process reproducible by basing the decision process on statistical criteria.
Selecting variables purely based on statistical properties would have likely resulted in networks that include only highly similar, closely related variables, which is again problematic for model estimation.
Also, as resulting estimates of network stability depend on which variables are included in the network, selecting vastly different variables across individuals would have confounded our comparisons of network stability.
Therefore, want to optimize variable selection in a way that makes idiographic networks somewhat comparable across individuals, while capturing the unique behaviors that are related to individual psychopathology.
We thus took a hybrid approach of variable selection based on theoretical as well as statistical grounds:

We constrained ouservelves to include six predictors, based on recent simulation work suggesting that graphical VAR performs well in recovering network structures of this size in comparibly small N=1 time series data <!--# cite mansueto and give detail on N in her work -->.
Each idiographic network included three composite variables (mean scores) which were expected to fluctuate similarly across participants: Positive Affect, negative Affect, and daily stress.
We also included a single-item variable capturing daily functioning.
Next, two additional variables will be selected per subject according to their rank on the following scoring metric:

$Ranking\ metric = (1 - {SW})_{T1} * (1 - {SW})_{T2} * {proportion\ completed}_{T1} * {proportion\ completed}_{T2}$

The Shapiro-Wilk test statistic ($SW$) tests the null hypothesis that a variable is sampled from a normal distribution, ranging from 0 to 1 [@YaziciYolacan2007, @ShapiroWilk1965].
Capturing the items mean and variance in this way, we wanted to select variables with minimal skew and maximal variance for a given individual.
These criteria were balanced against levels of missingness, because more missing and therefore imputed data would likely confound our network comparisons.
For that reason, we also wanted to avoid variables which comparably much missing data, or different means and variances, in the first or second half of the timeline.

## Stability metrics

We used three different metrics to compare idiographic networks estimated for the first and last 50 days of measurement.

### Profile correlations

Global network similarity can be described as the correlation of estimated edge weights.
Profile correlations range from -1 to 1, with 0 indicating no correlation.
Negative profile correlations are possible, but rarely found.
This metric classifies structural similarity by the *strength and direction* of all pairwise relationships in their respective *order*, but is agnostic to the fact that edges may be zero due to regularization.
When applied to regularized networks, it may therefor overestimate the similarity of regularized edges.

### Jaccard similarity

Jaccard similarity describes the proportion of replicated non-zero edges out of all estimated edges (edge that are non-zero in either network).
As such, it classifies similarity by *whether* there is a pairwise relationship while being agnostic to the strength or direction of that relationship.

### Proportion of recovered edge signs

To estimate the degree to which edge signs replicate across networks, we calculated the proportion edges with equal sign across network, out of all possible edges.
This measure thus classifies similarity by the *direction* of the pairwise relationship while being agnostic to the strength of the relationship.

## Explaining inter-individual variance

We explored what factors that may explain intra-individual variance in network stability using exploratory multivariate linear regression.
Linear models were fit for each stability metric separately.
Per metric, two sets of predictor were fit separately, one set containing subject-specific factors measured at baseline, and one set capturing statistical features of the diary data and network models.

+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Name                       | Item or scale                                                                                                                |
+:===========================+:=============================================================================================================================+
| Age                        | "What is your current age?"\                                                                                                 |
|                            | [0 = female, 1 = male]                                                                                                       |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Gender                     | "What is your sex?"                                                                                                          |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Recent Treatment           | "How long ago did the most recent treatment end?"\                                                                           |
|                            | [0 = currently in treatment : 4 = 5 years ago, 5 = never been in treatment]                                                  |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Happiness                  | "In the past 6 months, to what extent would you say you have been happy/satisfied/optimistic about yourself and your life?"\ |
|                            | [0= not at all : 7=very much]                                                                                                |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Life Satisfaction          | Satisfaction With Life Scale (SWLS)                                                                                          |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Personality                | NEO - Five Factor Inventory (NEO-FFI)                                                                                        |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| No. imputed                | total number imputed data point (sum T1 and T1)                                                                              |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Model fit                  | Bayesian Information Criterion (BIC)                                                                                         |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Sparcity                   | proportion of empty edges (average T1 and T2)                                                                                |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Changes in Positive Affect | $\Delta_{T1-T2}(1-SW_{PA})$                                                                                                  |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Changes in Negative Affect | $\Delta_{T1-T2}(1-SW_{NA})$                                                                                                  |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Changes in Stress          | $\Delta_{T1-T2}(1-SW_{Stress})$                                                                                              |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+
| Changes in Impairment      | $\Delta_{T1-T2}(1-SW_{Tasks})$                                                                                               |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------+

: (\#tab:regrVarTab) Predictor variables included in multivariate regression models

The set of baseline variables included of predictors was used in each model, consisting of person-specific and network-specific variables.
Person specific predictors included Gender, Age, duration since last treatment, and personality (extraversion, agreeablenes, neuroticism, conscientiousness, and openness to experience).
To possibly replicate findings of @MansuetoEtAl2020, life satisfaction and a one-item measure of happiness were also included.
Network specific predictors included sparcity and model fit, averaged across T1 and T2, as well as changes in the distribution of the four daily variables included in all networks (Positive Affect, negative affect, stress, and task impairment).
Variables scales are shown in Table \@ref(tab:regrVarTab).

```{r exludeMissing, eval = FALSE}

data  <- read.csv(here("data", "dd100_daily.csv"))    %>% select(-X)
N     <- length(unique(data$participantID)) # 112

# count nr of missing per px
idx_missing <- matrix(NA, N, 7)
colnames(idx_missing) <- c("ID", 
                           "CompletedTotal", 
                           "CompletedT1", 
                           "CompletedT2", 
                           "Include", 
                           "Var_Tasks_T1", 
                           "Var_Tasks_T2")

for (p in 1:N){
  # ID
  idx_missing[p,1] <- p
  # CompletedTotal 
  d <- filter(data, data$participantID == p)
  idx_missing[p,2] <-  unique(d$total.days)
  # CompletedT1 
  d1 <-  filter(d, day.response %in% 1:50, missingResponse == 1) # 1 = response present
  idx_missing[p,3] <- dim(d1)[1]
  # CompletedT2
  d2 <-  filter(d, day.response %in% 51:100, missingResponse == 1)
  idx_missing[p,4] <- dim(d2)[1]
  # also exclude participants with zero variance in 'tasks' variable
  d3 <- filter(d, day.response %in% 1:50)
  idx_missing[p,6] <- var(d3$tasks, na.rm = T) > 0
  d4 <- filter(d, day.response %in% 51:100)
  idx_missing[p,7] <- var(d4$tasks, na.rm = T) > 0
  # Include; TRUE if more than 70 responses overall, 
  # and more than 35 both T1 and T2, and non-zero var in 'tasks'
  idx_missing[p,5] <- idx_missing[p,2]>70 &
                      idx_missing[p,3]>35 &
                      idx_missing[p,4]>35 &  
                      idx_missing[p,6]==T & 
                      idx_missing[p,7]==T
}
saveRDS(idx_missing, here("data", "idx_missing.RDS"))

# track reasons for exclusion
which(idx_missing[ ,2]<=70)  # 20 fewer than 70 total
which(idx_missing[ ,3]<=35)  # 17 fewer than 15 t1
which(idx_missing[ ,4]<=35)  # 26 fewer than 15 t2
which(idx_missing[ ,6]==F)   # 7 no var tasks t1
which(idx_missing[ ,7]==F)   # 5 no var tasks t2

unionTot <- union(which(idx_missing[ ,4]<=35) , which(idx_missing[ ,3]<=35) ) # %>% length() # 27
unionT1T2 <- union ( which(idx_missing[ ,6]==F),  which(idx_missing[ ,7]==F) ) # %>% length() # 9
union (unionTot, unionT1T2 ) %>% length() # 33
112-33 # N = 73

# included IDs
idx_included <- idx_missing %>% 
  as.data.frame() %>% 
  filter(Include == TRUE)

# exclude participants
data <- filter(data, participantID %in% idx_included$ID)

# rename IDs for easy looping
data$participantID <- factor(data$participantID, 
                      levels = unique(data$participantID), 
                      labels = 1:length(unique(data$participantID))) %>% 
                      as.numeric()

# N: nr participants retained
N <- length(unique(data$participantID)) # 79

# compute composite variables for positive affect, negative affect, and stress severity
data$PosAffect <- (data$alert + data$active + data$attentive + 
                   data$determined + data$inspired) / 5
data$NegAffect <- (data$afraid + data$nervous + data$hostile + 
                   data$ashamed + data$upset) / 5
data$StressSev <- (data$severe1 + data$severe2 + data$severe3 +
                   data$severe4 + data$severe5 + data$severe6 + data$severe7) / 7

data_daily_raw <- data; rm(data) # keep copy of data after exclusion of participants

#------------------------------------------------------------------------
# rename participant IDs Baseline with same pipeline used for daily data
#------------------------------------------------------------------------
data <- data_baseline <- read.csv(here("data", "dd100_baseline.csv")) %>% select(-X)
# exclude participants
data <- filter(data, participantID %in% idx_included$ID)
# rename IDs for easy looping
data$participantID <- factor(data$participantID, 
                      levels = unique(data$participantID), 
                      labels = 1:length(unique(data$participantID))) %>% 
                      as.numeric()
# N: nr participants retained
N1 <- length(unique(data$participantID))
data_baseline <- data; rm(data)

saveRDS(data_baseline, file = here("data", "data_baseline.RDS"))
saveRDS(data_daily_raw, file = here("data", "data_daily_raw.RDS"))
```

```{r Kalman, eval = FALSE}
data      <- data_daily_raw
emaLabels <- data %>% 
  select(tasks:dpds32) %>% 
  colnames()

#   apply Kalman filter to impute at level of participant, based on full 100d
library("imputeTS")
for (p in 1:N){
    for (v in seq_along(emaLabels)){
      if (length(unique(na.omit(data[data$participantID == p, 5+v]))) > 1){
        data[data$participantID == p, 5+v] <- 
          na_kalman(data[data$participantID == p, 5+v]) # throws error, see Note below
      } else  data[data$participantID == p, 5+v] <- 
          unique(na.omit(data[data$participantID == p, 5+v]))
    }
}

# compute composite variables for positive affect, negative affect, and stress severity
data$PosAffect <- (data$alert + data$active + data$attentive + 
                   data$determined + data$inspired) / 5
data$NegAffect <- (data$afraid + data$nervous + data$hostile + 
                   data$ashamed + data$upset) / 5
data$StressSev <- (data$severe1 + data$severe2 + data$severe3 +
                   data$severe4 + data$severe5 + data$severe6 + data$severe7) / 7

emaLabels <-  data %>% 
              select(-(participantID:total.days)) %>% 
              colnames()

data_daily_imputed <- data # keep copy of imputed data

saveRDS(data_daily_imputed, file = here("data", "data_daily_imputed.RDS"))

# NOTE:
# error is thrown when assigning imputed data to df:
# 
# possible convergence problem: 'optim' gave code = 52 
# and message ‘ERROR: ABNORMAL_TERMINATION_IN_LNSRCH’            [,1]      [,2]
# 
# I checked the iterations with errors manually, the imputation and assignment seem to work despite error, so I continue.
# 
# example of itiration w errors: 
# i = 86; v = 41
# cbind( data_daily_imputed[data_daily_imputed$participantID == p, 5+v] , na_kalman(data[data_daily_imputed$participantID == p, 5+v]))
```

```{r detrending, eval = FALSE}

# We detrend at level of participant, using full 100d, regardless of significance level of linear trend
data <- data_daily_imputed
for (p in 1:N) {
  for (v in seq_along(emaLabels)){
    formula <- as.formula(paste0(emaLabels[v], " ~ 1 + day.response")) # define formula for linear trend
    trend_v <- lm(formula, data = data[data$participantID == p, ]) # fit model per person per var
    data[data$participantID == p, 5+v] <- residuals(trend_v) # detrend 
  }
}
data_detrended <- data # keep copy of data after detrending
saveRDS(data_detrended, file = here("Data", "data_detrended.RDS"))

# NOTE: 
# To check for significance of alpha, include below code in loop: 
# if (anova(trend_v)[["Pr(>F)"]][1] < 0.05) { ... } else next

```

```{r descriptives, eval = FALSE}

# prepare data frame to store variable descriptives per person per time period
EMA_descriptives <- data.frame(
  ID = rep(c(1:N), each = length(emaLabels)),
  Var = rep(seq_along(emaLabels), N),
  emaLabels = rep(c(emaLabels), N)
  )

# function to filter rows for T1 and T2 data
.filterData <- function(timeperiod = c("T1", "T2"), dat, p){
  if (timeperiod == "T1"){
    t <- 1:50
  } else if ( timeperiod == "T2"){
    t <- 51:100    
  } else t <- 1:100
  return( filter(dat, participantID == p, day.response %in% t) )
}

# extract variable descriptives
for (p in 1:N){
  
    raw_T1        <- .filterData("T1", data_daily_raw, p) 
    raw_T2        <- .filterData("T2", data_daily_raw, p)
    imputed_T1    <- .filterData("T1", data_daily_imputed, p)
    imputed_T2    <- .filterData("T2", data_daily_imputed, p)
    detrended_T1  <- .filterData("T1", data_detrended, p)
    detrended_T2  <- .filterData("T2", data_detrended, p)
  
    for (v in seq_along(emaLabels)){
      
      # dynamic index for EMA_descriptives df
      idx <- (p-1)*length(emaLabels)+v
      
      # proportion completed T1 and T2
      EMA_descriptives$nr_imputed_T1[idx] <- sum(is.na(raw_T1[ ,5+v]))
      EMA_descriptives$nr_imputed_T2[idx] <- sum(is.na(raw_T2[ ,5+v]))
      EMA_descriptives$completed_T1[idx]  <- sum(!is.na(raw_T1[ ,5+v]))/50
      EMA_descriptives$completed_T2[idx]  <- sum(!is.na(raw_T2[ ,5+v]))/50
      
      # (1-Normality) Raw Variables T1 and T2:
      if (length(unique(na.omit(raw_T1[ ,5+v]))) > 1) {
              EMA_descriptives$norm_T1[idx] <- 
                1-shapiro.test(raw_T1[ ,5+v])[[1]] 
      } else  EMA_descriptives$norm_T1[idx] <- 0
      if (length(unique(na.omit(raw_T2[ ,5+v]))) > 1) {
              EMA_descriptives$norm_T2[idx] <- 
                1-shapiro.test(raw_T2[ ,5+v])[[1]] 
      } else  EMA_descriptives$norm_T2[idx] <- 0
      # (1-Normality) Detrended Variables T1 and T2
      if (length(unique(na.omit(raw_T1[ ,5+v]))) > 1) {
              EMA_descriptives$norm_detrended_T1[idx] <- 
                1-shapiro.test(detrended_T1[ ,5+v])[[1]]
      } else  EMA_descriptives$norm_detrended_T1[idx] <- 
        0
      if (length(unique(na.omit(raw_T2[ ,5+v]))) > 1) {
              EMA_descriptives$norm_detrended_T2[idx] <- 
                1-shapiro.test(detrended_T2[ ,5+v])[[1]]
      } else  EMA_descriptives$norm_detrended_T2[idx] <- 
        0
      
      # Means and SDs for T1 and T2:
      EMA_descriptives$mean_raw_T1[idx]     <- raw_T1[ ,5+v]     %>% mean(na.rm = TRUE)
      EMA_descriptives$mean_raw_T2[idx]     <- raw_T2[ ,5+v]     %>% mean(na.rm = TRUE)
      EMA_descriptives$sd_raw_T1[idx]       <- raw_T1[ ,5+v]     %>% sd(na.rm = TRUE) 
      EMA_descriptives$sd_raw_T2[idx]       <- raw_T2[ ,5+v]     %>% sd(na.rm = TRUE)
      
      EMA_descriptives$mean_imputed_T1[idx] <- imputed_T1[ ,5+v] %>% mean(na.rm = TRUE)
      EMA_descriptives$mean_imputed_T2[idx] <- imputed_T2[ ,5+v] %>% mean(na.rm = TRUE)
      EMA_descriptives$sd_imputed_T1[idx]   <- imputed_T1[ ,5+v] %>% sd(na.rm = TRUE) 
      EMA_descriptives$sd_imputed_T2[idx]   <- imputed_T2[ ,5+v] %>% sd(na.rm = TRUE)
      
      EMA_descriptives$mean_detrended_T1[idx] <- detrended_T1[ ,5+v] %>% mean(na.rm = TRUE)
      EMA_descriptives$mean_detrended_T2[idx] <- detrended_T2[ ,5+v] %>% mean(na.rm = TRUE)
      EMA_descriptives$sd_detrended_T1[idx]   <- detrended_T1[ ,5+v] %>% sd(na.rm = TRUE) 
      EMA_descriptives$sd_detrended_T2[idx]   <- detrended_T2[ ,5+v] %>% sd(na.rm = TRUE) 
   }
}

# compute rank stat raw data
EMA_descriptives$rank_stat <- EMA_descriptives$completed_T1 * 
                              EMA_descriptives$completed_T2 * 
                              EMA_descriptives$norm_T1 * 
                              EMA_descriptives$norm_T2

# rank stat on detrended data
EMA_descriptives$rank_stat_detrended <- EMA_descriptives$completed_T1 * 
                                        EMA_descriptives$completed_T2 * 
                                        EMA_descriptives$norm_detrended_T1 * 
                                        EMA_descriptives$norm_detrended_T2

cor(EMA_descriptives$rank_stat, EMA_descriptives$rank_stat_detrended) # .96, so shouldn't make a difference

saveRDS(EMA_descriptives, file = here("Data", "EMA_descriptives.RDS"))



# NOTE
# v = 1: first EMA Variable; located at 6th column in data (thus 5+v)
# ShapiroWilk test stat: 0 = perfect normality, 1 = deviation from normality. 
# Because we want to prioritize more normally distributed variables, we use 1-ShapiroWilk.
# As result, a higher rank statistic means better properties.
```

```{r NetworkEstimation, eval = FALSE}

# empty data frame to store path estimates in long format (two rows per participant, 1 for T1, 1 for T2)
networks <- data.frame("ID" = rep(1:N, each=2),
                      "timeperiod" = rep(c("T1", "T2"), N),
                      # 3:17 Contemporaneous network: lower triangle in col by col format
                      "PCC_PA_NA" = NA,
                      "PCC_PA_Stress" = NA,
                      "PCC_PA_Task" = NA,
                      "PCC_PA_Rank1" = NA,
                      "PCC_PA_Rank2" = NA,
                      "PCC_NA_Stress" = NA,
                      "PCC_NA_tasks" = NA,
                      "PCC_NA_Rank1" = NA,
                      "PCC_NA_Rank2" = NA,
                      "PCC_Stress_tasks" = NA,
                      "PCC_Stress_Rank1" = NA,
                      "PCC_Stress_Ranks2" = NA,
                      "PCC_Tasks_Rank1" = NA,
                      "PCC_Tasks_Rank2" = NA,
                      "PCC_Rank1_Rank2" = NA,
                      # 18:53 Temporal networks: full matrix in col by col format
                      "PDC_PA_PA" = NA,
                      "PDC_PA_NA" = NA,
                      "PDC_PA_Stress" = NA,
                      "PDC_PA_Tasks" = NA,
                      "PDC_PA_Rank1" = NA,
                      "PDC_PA_Rank2" = NA,
                      "PDC_NA_PA" = NA,
                      "PDC_NA_NA" = NA,
                      "PDC_NA_Stress" = NA,
                      "PDC_NA_Tasks" = NA,
                      "PDC_NA_Rank1" = NA,
                      "PDC_NA_Rank2" = NA,
                      "PDC_Stress_PA" = NA,
                      "PDC_Stress_NA" = NA,
                      "PDC_Stress_Stress" = NA,
                      "PDC_Stress_Tasks" = NA,
                      "PDC_Stress_Rank1" = NA,
                      "PDC_Stress_Rank2" = NA,
                      "PDC_Tasks_PA" = NA,
                      "PDC_Tasks_NA" = NA,
                      "PDC_Tasks_Stress" = NA,
                      "PDC_Tasks_Tasks" = NA,
                      "PDC_Tasks_Rank1" = NA,
                      "PDC_Tasks_Rank2" = NA,
                      "PDC_Rank1_PA" = NA,
                      "PDC_Rank1_NA" = NA,
                      "PDC_Rank1_Stress" = NA,
                      "PDC_Rank1_Tasks" = NA,
                      "PDC_Rank1_Rank1" = NA,
                      "PDC_Rank1_Rank2"   = NA,
                      "PDC_Rank2_PA" = NA,
                      "PDC_Rank2_NA" = NA,
                      "PDC_Rank2_Stress" = NA,
                      "PDC_Rank2_Tasks" = NA,
                      "PDC_Rank2_Rank1" = NA,
                      "PDC_Rank2_Rank2" = NA,
                      # 54
                      "BIC" = NA
                      )

# index columns for contemporaneous network (PPC: 3:17) and temporal networks (PDC 18:53) in Networks df
idx_PCC <- 3:17
idx_PDC <- 18:53

# data frame for main outcome statistics
comparisons <- data.frame(participantID = 1:N)

# fit networks. 
# Specification a la BeckJackson2020, gamma = 0, Lambda range 0.025 to 1
for (p in 1:N){
  # if( p %in% c(4)) { next }
  # filter data by participant
  d_T1 <- filter(data, participantID==p, day.response %in% 1:50)
  d_T2 <- filter(data, participantID==p, day.response %in% 51:100)
  #  select two highest ranking DPDS/behavior variables, higher rank stat = better
  selectVar  <- filter(EMA_descriptives, 
                  EMA_descriptives$ID == p, 
                  EMA_descriptives$emaLabels %in% 
                    emaLabels[c(11:23, 31:60)]
                  )
  selectVar <- selectVar[order(selectVar$rank_stat_detrended, decreasing = TRUE), ]
  Rank1       <- selectVar[1, 3]
  Rank2       <- selectVar[2, 3]
  # log name of DPDS Variables
  comparisons$Rank1[p] <- Rank1
  comparisons$Rank2[p] <- Rank2
  # log total nr imputed data points
  comparisons$nr_imputed[p] <- filter(data_daily_raw, participantID==p, day.response %in% 1:100) %>%
    select(PosAffect, NegAffect, StressSev, tasks, all_of(Rank1), all_of(Rank2)) %>%
    is.na() %>%
    sum()
  # define individualized networks
  d_T1 <- select(d_T1, 
                 day.response, 
                 PosAffect, 
                 NegAffect, 
                 StressSev, 
                 tasks, 
                 all_of(Rank1), 
                 all_of(Rank2)
                 )
  d_T2 <- select(d_T2, 
                 day.response, 
                 PosAffect, 
                 NegAffect, 
                 StressSev, 
                 tasks, 
                 all_of(Rank1), 
                 all_of(Rank2)
                 ) 
  # BeckJackson2020 used gamma = 0, Lambda 0.025:1 by 0.025
  netw_T1 <- graphicalVAR(d_T1, 
                          beepvar = "day.response",
                          gamma = 0,
                          lambda_beta = seq(.025, 1, .0125)
                          )
  cat(paste("T1 participant",p ,"converged"))
  netw_T2 <- graphicalVAR(d_T2, 
                          beepvar = "day.response",
                          gamma = 0,
                          lambda_beta = seq(.025, 1, .0125)
                          )
  cat(paste("T2 participant",p ,"converged"))
  
  # store full network objects in global environment for later inspection
  assign(paste0("ID",p,"_T1"), netw_T1)
  assign(paste0("ID",p,"_T2"), netw_T2)
  
  # save network objects for detailed inspection / plotting
  saveRDS(netw_T1, here("data", "network_objects", paste0("ID",p,"_T1.RDS")))
  saveRDS(netw_T2, here("data", "network_objects", paste0("ID",p,"_T2.RDS")))
  
  # extract path estimates for easy comparison
  networks[networks$ID == p, idx_PCC] <-
    rbind(netw_T1$PCC[lower.tri(netw_T1$PCC)] %>%
            as.numeric()%>%
            as.vector() %>%
            round(digits=4),
          netw_T2$PCC[lower.tri(netw_T2$PCC)] %>%
            as.numeric()%>%
            as.vector() %>%
            round(digits=4)
          )
  networks[networks$ID == p, idx_PDC] <- 
    rbind(netw_T1$PDC %>%
            as.numeric()%>%
            as.vector()%>%
            round(digits = 4),
          netw_T2$PDC %>%
            as.numeric()%>%
            as.vector()%>%
            round(digits = 4)
          )
  networks$BIC[networks$ID == p] <- rbind( netw_T1$EBIC, netw_T2$EBIC)
}

```

```{r NetwComparisons, eval = FALSE}
# Network descriptives:
## empty edges
networks$nr_zero_PCC        <- rowSums(networks[ ,idx_PCC] == 0)
networks$nr_zero_PDC        <- rowSums(networks[ ,idx_PDC] == 0)
## proportion of empty edges
networks$pr_zero_PCC        <- rowMeans(networks[ ,idx_PCC] == 0) * 100 %>% as.numeric() %>%round( digits = 2)
networks$pr_zero_PDC        <- rowMeans(networks[ ,idx_PDC] == 0) * 100 %>% as.numeric() %>%round( digits = 2)
## estimated edges total
networks$nr_estimated_PCC   <- rowSums(networks[ ,idx_PCC] != 0)
networks$nr_estimated_PDC   <- rowSums(networks[ ,idx_PDC] != 0)
## estimated positive edges
networks$nr_pos_PCC         <- rowSums(networks[ ,idx_PCC] > 0)
networks$nr_pos_PDC         <- rowSums(networks[ ,idx_PDC] > 0)
## estimated positive edges
networks$nr_neg_PCC         <- rowSums(networks[ ,idx_PCC] < 0)
networks$nr_neg_PDC         <- rowSums(networks[ ,idx_PDC] < 0)
## "Connectivity (% possible edges)" a la EpskampEA False Alarm paper
networks$connectivity_PCC   <- round( networks$nr_estimated_PCC /length(idx_PCC) * 100, 2)
networks$connectivity_PDC   <- round( networks$nr_estimated_PDC /length(idx_PDC) * 100, 2)
  
NrEmptyPCC <- sum(networks$pr_zero_PCC == 100) # 1 empty contemp net total
NrEmptyPDC <- sum(networks$pr_zero_PDC == 100) # 46 empty temp net total

# Compute networks comparison statistics
for (p in 1:N) {
  # dynamic index for T1 and T2 rows per person in 'networks' data frame
  idx_p_T1  <- (p-1)*2+1
  idx_p_T2  <- (p-1)*2+2
  PCC_T1    <- networks[idx_p_T1, idx_PCC] %>% as.numeric()
  PCC_T2    <- networks[idx_p_T2, idx_PCC] %>% as.numeric()
  PDC_T1    <- networks[idx_p_T1, idx_PDC] %>% as.numeric()
  PDC_T2    <- networks[idx_p_T2, idx_PDC] %>% as.numeric()
  # correlation of all edge weights
  comparisons$PCCs_cor[p] <- cor(PCC_T1, PCC_T2, method = "spearman")  
  comparisons$PDCs_cor[p] <- cor(PDC_T1, PDC_T2, method = "spearman") 
  # Correlation non-zero edge weights
  comparisons$PCCs_cor_non0[p] <- cor(PCC_T1[PCC_T1!=0&PCC_T2!=0],PCC_T2[PCC_T1!=0&PCC_T2!=0], method = "spearman")
  comparisons$PDCs_cor_non0[p] <- cor(PDC_T1[PDC_T1!=0&PDC_T2!=0],PCC_T2[PDC_T1!=0&PDC_T2!=0], method = "spearman")
  # Jaccard similarity, https://en.wikipedia.org/wiki/Jaccard_index#Similarity_of_asymmetric_binary_attribute
  # proportion of shared non-zero edges relative to number of edges which are non-zero in either, but not both, networks 
  comparisons$PCCs_Jaccard[p] <-   sum(PCC_T1!=0 & PCC_T2!=0) / sum(PCC_T1!=0 | PCC_T2!=0)
  comparisons$PDCs_Jaccard[p] <-   sum(PDC_T1!=0 & PDC_T2!=0) / sum(PDC_T1!=0 | PDC_T2!=0)
  # proportion empty edges both netw
  comparisons$PCCs_prop_empty[p]     <- mean( PCC_T1 == 0 & PCC_T2 == 0)
  comparisons$PDCs_prop_empty[p]     <- mean( PDC_T1 == 0 & PDC_T2 == 0)
  # proportion of edges with equal sign or both zero in network
  comparisons$PCCs_prop_equ_sign[p]  <- mean( (PCC_T1 == 0 & PCC_T2 == 0) |
                                           (PCC_T1 > 0 & PCC_T2 > 0) |
                                           (PCC_T1 < 0 & PCC_T2 < 0))
  comparisons$PDCs_prop_equ_sign[p]  <- mean( (PDC_T1 == 0 & PDC_T2 == 0) |
                                           (PDC_T1 > 0 & PDC_T2 > 0) |
                                           (PDC_T1 < 0 & PDC_T2 < 0))
  # proportion of edges with equal sign, excluding zeros
  comparisons$PCCs_prop_equ_sign_non0[p]  <- mean((PCC_T1 > 0 & PCC_T2 > 0) |
                                           (PCC_T1 < 0 & PCC_T2 < 0))
  comparisons$PDCs_prop_equ_sign_non0[p]  <- mean((PDC_T1 > 0 & PDC_T2 > 0) |
                                           (PDC_T1 < 0 & PDC_T2 < 0))
  # BIC avg across T1 and T2
  comparisons$avg_BIC[p] <- networks[networks$ID==p, 54] %>% mean()
}

# compute difference in normality scores of composite variables
 comparisons <-  EMA_descriptives %>% 
    filter(emaLabels == "PosAffect") %>%
    transmute(participantID = ID, 
              diff_norm_PA = norm_T1 - norm_T2) %>%
    right_join(comparisons, by = "participantID")
 
 comparisons <-  EMA_descriptives %>% 
    filter(emaLabels == "NegAffect") %>%
    transmute(participantID = ID, 
              diff_norm_NA = norm_T1 - norm_T2) %>%
    right_join(comparisons, by = "participantID")
  
 comparisons <-  EMA_descriptives %>% 
    filter(emaLabels == "StressSev") %>%
    transmute(participantID = ID, 
              diff_norm_Stress = norm_T1 - norm_T2) %>%
    right_join(comparisons, by = "participantID") 
  
  
 comparisons <-  EMA_descriptives %>% 
    filter(emaLabels == "tasks") %>%
    transmute(participantID = ID, 
              diff_norm_Tasks = norm_T1 - norm_T2) %>%
    right_join(comparisons, by = "participantID")
  

# saveRDS(networks, here("data", "networks.RDS"))
# saveRDS(comparisons, here("data", "comparisons.RDS"))
 ranksincluded <- c(comparisons$Rank1, comparisons$Rank2) %>% as.factor() %>% summary()
 > comparisons$PCCs_cor %>% summary()
#  ---------------------------------------------
#  sascha False Alarm code https://osf.io/xh87b/
#  sForbes Quantifying code https://osf.io/qcrjk/
```

```{r, eval = F}
descriptives  <-  data_baseline %>% filter(gender %in% c(0,1))  %>%
  #group_by(gender) %>%
  summarize(across(age:neoC), 
            list(  
    Mean = mean,
    Median = median,
    SD = sd
  )
  )

descriptives[, -1] <- printnum(descriptives[, -1])

apa_table(
  descriptives
  , caption = "Descriptive statistics of correct recall by dosage."
  , note = "This table was created with apa_table()."
  , escape = TRUE

```

# Results

## RQ1: Network stability within people

Of the original sample ($N_original=116$), four participant's IDs had been excluded by the original authors.
Of the available 112 participants, twenty-seven had missed entries on more than 15 days in T1 or T2 each, and nine participants exhibited zero variance in daily task impairment.
These participants were excluded from the analysis ($N_{union excluded}=33$).
Of the remaining participants ($N = 79$), fifty-two participants were male, one person did not indicate gender.
TODO AGE

-   Brief summary of estimation process: with which parameters did model converge or not? provide estimates with different gamma and lamba in Appendix, together with violin plots ( als dots ) of outcome variables (nr of empty networks, failed convergions, and plots of outcome measures)
-   describe resulting networks (prop empty edges etcs
-   convergence
-   nr of empty networks
-   explain dot plot and interpret values in context of that the indices measure
-   report mean, median, sd of the indices

```{r comparisonsplotPCC}
cors <- comparisons %>%
  select("Edge weight correlation" = PCCs_cor, 
         "Jaccard similarity" = PCCs_Jaccard, 
         "Recovered edge signs (%)" = PCCs_prop_equ_sign_non0) %>%
  gather()

png("ComparisonViolin.png", width = 200, height = 200, units='mm', res = 300)
ggplot(cors, aes(x = key, y = value)) +
  geom_abline( slope = 0, intercept = 0, colour = "grey") +
  geom_violin(alpha = 0.3, colour = "white", fill = "grey") +
  geom_dotplot(binaxis= "y",
               stackdir = "center",
               dotsize = 0.3,
               fill = 1,
               stackratio = 2) +
  theme_apa() +
  labs( title = "Temporal stability contemporaneous idiographic networks",  y = "", x = "")
dev.off() 

```

## RQ2: Network stability across metrics

Stability estimates within people displayed distinct distributions, which is not surprising given that they evaluate network similarity on different features.As a high proportion of temporal networks were empty, and estimated temporal networks were highly unstable within participants, we focused on stability estimates of contemporaneous networks for all further comparisons.

To understand how individual network structures are evaluated differently across metrics, we visualized the metrics together as a function of network sparcity in Figure \@ref(ref:plotBubblePCCCap).
TODO EXPLAIN GRAPH AND INTERPRET

(ref:plotBubblePCCCap) Stability metrics for contemporaneous networks as a function of network sparcity.

```{r plotBubblePCC, fig.cap= "(ref:plotBubblePCCCap)"}
png("Bubble.png", width = 250, height = 200, units='mm', res = 300)

comparisons %>%
ggplot( aes(x = PCCs_prop_empty, 
            y = PCCs_cor, 
            size = PCCs_prop_equ_sign_non0 , 
            fill = PCCs_Jaccard)) + 
  geom_point(alpha = 0.6, shape = 23, color = "black", name = "Jaccard index") +
  scale_size_continuous(range = c(2,8), name = "Edge signs replicated (%)") +
  labs(x="Network sparsity (%)", y="Edge weight correlations", title = "Contemporaneous networks") +
  theme_apa() +
  scale_fill_viridis_c(name = "Jaccard index")
dev.off()
```


```{r plotBubblePCC, fig.cap= "(ref:plotBubblePCCCap)", fig.fullwidth=TRUE}
#pdf("bubble.pdf", width = 10, height = 7 )
comparisons %>%
ggplot( aes(x = PCCs_prop_empty, 
            y = PCCs_cor, 
            size = PCCs_prop_equ_sign_non0 , 
            fill = PCCs_Jaccard)) + 
  geom_point(alpha = 0.6, shape = 23, color = "black", name = "Jaccard index") +
  scale_size_continuous(range = c(2,8), name = "Edge signs replicated (%)") +
  labs(x="Network sparsity (%)", y="Edge weight correlations", title = "Contemporaneous networks") +
  theme_apa() +
  scale_fill_viridis_c(name = "Jaccard index")
#dev.off()
```

```{r antecendents, eval = F}

data_merged <- inner_join(data_baseline, comparisons, by = "participantID")
saveRDS(data_merged, here("data", "data_merged.RDS"))

predictors_person  <- "~ 1 + gender + age + recentTreatment + happy + swlsMean + neoN + neoE + neoO + neoA + neoC"

predictors_timeseries <- "~ 1 + nr_imputed + avg_BIC + PCCs_prop_empty + diff_norm_PA + diff_norm_NA + diff_norm_Stress + diff_norm_Tasks"

fit.Cor_pers         <- lm(formula = as.formula(paste0("PCCs_cor", predictors_person)), data = data_merged) %>% lm.beta()
fit.Jacc_pers        <- lm(formula = as.formula(paste0("PCCs_Jaccard", predictors_person)), data = data_merged) %>% lm.beta()
fit.EquSignNon0_pers <- lm(formula = as.formula(paste0("PCCs_prop_equ_sign_non0", predictors_person)), data = data_merged) %>% lm.beta()

summary(fit.Cor_pers) # neo C, swls
summary(fit.Jacc_pers) #neo a c age?
summary(fit.EquSignNon0_pers) # ?swl

fit.Cor_stat         <- lm(formula = as.formula(paste0("PCCs_cor", predictors_timeseries)), data = data_merged) %>% lm.beta()
fit.Jacc_stat        <- lm(formula = as.formula(paste0("PCCs_Jaccard", predictors_timeseries)), data = data_merged) %>% lm.beta()
fit.EquSignNon0_stat <- lm(formula = as.formula(paste0("PCCs_prop_equ_sign_non0", predictors_timeseries)), data = data_merged) %>% lm.beta()
summary(fit.Cor_stat) #-
summary(fit.Jacc_stat) # bic, empty
summary(fit.EquSignNon0_stat) # empty
```

## RQ3: Network stability across people

### Profile correlations

### Jaccard similarity

### Proportion of recovered edge signs

```{r examplePx, eval = TRUE}
# choose 2 participants with high vs low PCC cor, but similar density
px <- data_merged %>%
  filter(
    PCCs_prop_empty < 0.55,
    nr_imputed < 5
  ) %>% arrange (PCCs_cor) %>% filter(participantID %in% c(53, 45))
# 53 low  cor 0.1823801,  dpds25 dpds21
# 45 high cor 0.6480437, passive dpds24
# ebics most similar in t1 and t2

plotcolours53 <- c('#a6d854','#66c2a5','#fc8d62','#8da0cb','#E2A76F',"#E38AAE")
plotcolours45 <- c('#a6d854','#66c2a5','#fc8d62','#8da0cb','#C19A6B',"#C48793")

maxEdge <- networks %>% filter( ID %in% c(53, 45)) %>%
  select(idx_PCC)  %>% abs() %>% max()  # 0.469

# PX 53 -------------------------------------
# Px53 DPDS25: I acted on impulse while feeling upset.
# Px53 DPDS21: I worried about being abandoned.
# 53 low 0.1823801 low;  dpds25 dpds21 
namesPx53 <- c("PA", "NA", "Stress", "Task", "Impuls", "Worry")

dataPX53 <- data_daily_raw %>% 
filter( participantID==53, day.response %in% 1:100) %>%
  # rescale to 0.0 - 1 (max)
  mutate(PosAffect_rescaled = PosAffect * 1/max(na.omit(PosAffect)),
         NegAffect_rescaled = NegAffect * 1/max(na.omit(NegAffect)),
         StressSev_rescaled = StressSev * 1/max(na.omit(StressSev)),
         tasks_rescaled     = tasks * 1 /max(na.omit(tasks)),
         dpds25             = dpds25 * 1 /max(na.omit(dpds25)),
         dpds21             = dpds21 * 1 /max(na.omit(dpds21)),
         ) %>%
  select(day.response, 
         PosAffect_rescaled, 
         NegAffect_rescaled, 
         StressSev_rescaled, 
         tasks_rescaled, 
         dpds25, 
         dpds21) %>% 
  rename("Positive Affect" = PosAffect_rescaled,
         "Negative Affect" = NegAffect_rescaled,
         "Stress" = StressSev_rescaled,
         "Task impairment" = tasks_rescaled,
         "Impulsive while upset" = dpds25,
         "Worry about abandonment" = dpds21) %>%
  melt( id.vars = "day.response") %>% 
  rename( "Variable" = variable)

# PX 45 -------------------------------------
# 45 high cor 0.6480437, passive dpds24
namesPx45 <- c("PA", "NA", "Stress", "Task", "Passive", "Unusual")

dataPX45 <- data_daily_raw %>% 
filter( participantID==45, day.response %in% 1:100) %>%
  # rescale to 0.0 - 1 (max)
  mutate(PosAffect_rescaled = PosAffect * 1/max(na.omit(PosAffect)),
         NegAffect_rescaled = NegAffect * 1/max(na.omit(NegAffect)),
         StressSev_rescaled = StressSev * 1/max(na.omit(StressSev)),
         tasks_rescaled     = tasks * 1/max(na.omit(tasks)),
         passive            = passive * 1/max(na.omit(passive)),
         dpds24             = dpds24 * 1/max(na.omit(dpds24))
         ) %>%  
  select(day.response, 
         PosAffect_rescaled, 
         NegAffect_rescaled, 
         StressSev_rescaled, 
         tasks_rescaled, 
         passive, 
         dpds24)  %>% 
  rename("Positive Affect" = PosAffect_rescaled,
         "Negative Affect" = NegAffect_rescaled,
         "Stress" = StressSev_rescaled,
         "Impairment daily tasks" = tasks_rescaled,
         "Passive behavior" = passive,
         "Unusual behavior" = dpds24) %>%
  melt( id.vars = "day.response") %>% 
  rename( "Variable" = variable)

```

## Examples

Two participants were selected for illustration.
We selected these participants to exemplify cases of relatively high and low temporal stability, while ensuring other potentially confounding features were similar.
Participant 53 (P35) and participant 45 (P45) satisfied these criteria.
Their networks contained only 2 and 3 imputed data points, respectively.
Their contemporaneous networks had similar levels of sparcity ($Sparcity_{P53} = .53$; $Sparcity_{P45} = .40$), and their model fit was most similar given the previous criteria ($Mean_{BIC P53} = 196.66$;$Mean_{BIC P45} = 236.66$).

Figure \@(ref:networks) shows estimated contemporaneous networks of participant 53 at T1 and T2.
Daily item ratings across T1 and T2 are shown in Figure TODO. The networks of participant 53 exhibited relatively low temporal stability.
The similarity of global network structure was low, $r_{Spearman P53} = .18$.
Jaccard similarity was low, $Jaccard_P53 = .14$.
Only one of the six estimated edges had the same sign at T1 and T2.

Means, standard deviations, and changes in distiributions of daily measures for participant 53 and 45 are shown in Table \@\ref(tab:EMAdescr).

(ref:networks) Contemporaneous network structures of Participant 53 and 45 at T1 and T2.

```{r ExampleNetw, fig.cap="(ref:networks)"}
png("networks.png", width = 300, height = 300, units='mm', res = 300 )
layout(matrix(c(1,2,3,4), 2, 2, byrow = T), widths = c(1, 1))

ID53_T1$PCC %>%
  qgraph(
    DoNotPlot = F,
    title = "Participant 53 Contemporaneous T1",
    title.cex = 1.5,
    maximum = maxEdge,
    edge.labels = TRUE,
    edge.label.cex = 2,
    theme="colorblind",
    negDashed = TRUE,
    color = plotcolours53,
    labels = namesPx53,
    label.cex = 1.3,
    vTrans = 120
    ); #box("figure")

ID53_T2$PCC %>%
  qgraph(
    DoNotPlot = F,
    title = "Participant 53 Contemporaneous T2",
    title.cex = 1.5,
    maximum = maxEdge,
    edge.labels = TRUE,
    edge.label.cex = 2,
    theme="colorblind",
    negDashed = TRUE,
    color = plotcolours53,
    labels = namesPx53,
    label.cex = 1.3,
    vTrans = 120
 #   nodeNames = c("Positive Affect","Negative Affect" ,"Stress" ,"Impairment daily tasks" ,"Impulsive while upset" ,"Worry about abandonment")
#    legend.cex = 0.5
    ); #box("figure")

ID45_T1$PCC %>%
  qgraph(
    title = "Participant 45 Contemporaneous T1",
    title.cex = 1.5,
    DoNotPlot = F,
    maximum = maxEdge,
    edge.labels = TRUE,
    edge.label.cex = 2,
    theme="colorblind",
    negDashed = TRUE,
    color = plotcolours45,
    labels = namesPx45,
    label.cex = 1.3,
    vTrans = 120
    ); #box("figure")

ID45_T2$PCC %>%
  qgraph(
    title = "Participant 45 Contemporaneous T2",
    title.cex = 1.5,
    DoNotPlot = F,
    maximum = maxEdge,
    edge.labels = TRUE,
    edge.label.cex = 2,
    theme="colorblind",
    negDashed = TRUE,
    color = plotcolours45,
    labels = namesPx45,
    label.cex = 1.3,
    vTrans = 120
 #   nodeNames = c("Positive Affect","Negative Affect" ,"Stress" ,"Impairment daily tasks" ,"Passive behavior" ,"Unusual behavior")
    ); #box("figure")
dev.off()
```

```{r}
 #DPDS25: I acted on impulse while feeling upset.
# DPDS21: I worried about being abandoned.
png("timeseries53.png", width = 300, height = 100, units='mm', res = 300)

# Behavior and DPD vars are on 0:7 already
dataPX53 <- data_daily_raw %>% 
filter( participantID==53, day.response %in% 1:100) %>%
  # rescale to range 0-7 for plotting, with 7 reflecting highest score of this participant
  mutate(PosAffect_rescaled = PosAffect * 1/max(na.omit(PosAffect)),
         NegAffect_rescaled = NegAffect * 1/max(na.omit(NegAffect)),
         StressSev_rescaled = StressSev * 1/max(na.omit(StressSev)),
         tasks_rescaled     = tasks * 1 /max(na.omit(tasks)),
         dpds25 = dpds25 * 1 /max(na.omit(dpds25)),
         dpds21 = dpds21 * 1 /max(na.omit(dpds21)),
         ) %>%
  select(day.response, 
         PosAffect_rescaled, 
         NegAffect_rescaled, 
         StressSev_rescaled, 
         tasks_rescaled, 
         dpds25, 
         dpds21) %>% 
  rename("Positive Affect" = PosAffect_rescaled,
         "Negative Affect" = NegAffect_rescaled,
         "Stress" = StressSev_rescaled,
         "Impairment daily tasks" = tasks_rescaled,
         "Impulsive while upset" = dpds25,
         "Worry about abandonment" = dpds21) %>%
  melt( id.vars = "day.response") %>% 
  rename( "Variable" = variable)

dataPX53 %>%  ggplot(
  aes(x = day.response, y = value, colour = Variable, group=Variable)
  ) +
  geom_line(size = 1.1, alpha = 0.7) +
  coord_fixed(ratio = 1000/70) +
  theme_apa(box = TRUE) +
  theme(legend.position="bottom") +
  labs( x = "Day", y = "Rating (scaled)", title = "Participant 53") +
  scale_color_manual(values= plotcolours53)
# comparisons %>% filter( participantID %in% c(45)) %>% select(Rank1, Rank2)
# passive , # dpds24 unusual
dev.off()

png("timeseries45.png", width = 300, height = 100, units='mm', res = 300)
# Behavior and DPD vars are on 0:7 already
dataPX45 <- data_daily_raw %>% 
filter( participantID==45, day.response %in% 1:100) %>%
  # rescale to range 0-7 for plotting, with 7 reflecting highest score of this participant
  mutate(PosAffect_rescaled = PosAffect * 1/max(na.omit(PosAffect)),
         NegAffect_rescaled = NegAffect * 1/max(na.omit(NegAffect)),
         StressSev_rescaled = StressSev * 1/max(na.omit(StressSev)),
         tasks_rescaled     = tasks * 1/max(na.omit(tasks)),
         passive = passive * 1/max(na.omit(passive)),
         dpds24 = dpds24 * 1/max(na.omit(dpds24))
         ) %>%  
  select(day.response, 
         PosAffect_rescaled, 
         NegAffect_rescaled, 
         StressSev_rescaled, 
         tasks_rescaled, 
         passive, 
         dpds24)  %>% 
  rename("Positive Affect" = PosAffect_rescaled,
         "Negative Affect" = NegAffect_rescaled,
         "Stress" = StressSev_rescaled,
         "Impairment daily tasks" = tasks_rescaled,
         "Passive behavior" = passive,
         "Unusual behavior" = dpds24) %>%
  melt( id.vars = "day.response") %>% 
  rename( "Variable" = variable)

dataPX45 %>%  ggplot(
  aes(x = day.response, y = value, colour = Variable, group=Variable)
  ) +
  geom_line(size = 1.1, alpha = 0.7) +
  coord_fixed(ratio = 1000/70) +
  theme_apa(box = TRUE) +
  theme(legend.position="bottom") +
  labs( x = "Day", y = "Rating (scaled)", title = "Participant 45") +
  scale_color_manual(values= plotcolours45)

dev.off()
```





| Participant | Variable                         | $Mean(SD)_{T1}$ | $Mean(SD)_{T2}$ | $SW_\Delta{T1-T2}$ |
|:-----------:|----------------------------------|-----------------|-----------------|:-------------------|
|     P53     | Positive Affect                  | 1.27 (0.67)     | 1.41 (0.51)     | 0.01               |
|             | Negative Affect                  | 0.66 (0.71)     | 0.49 (0.40)     | 0.03               |
|             | Stress                           | 0.12 (0.21)     | 0.09 (0.19)     | -0.10              |
|             | Task Impairment                  | 1.0( 0.83)      | 1.22 (0.86)     | 0.03               |
|             | Impulsive while upset (DPDS25)   | 0.08 (0.56)     | 0.04 (0.28)     | 0.00               |
|             | Worry about abandonment (DPDS21) | 0.18 (1.02)     | 0.04 ( 0.28)    | -0.05              |
|     P45     | Positive Affect                  | 2.18 (0.55)     | 2.16 (0.50)     | -0.09              |
|             | Negative Affect                  | 0.69 (0.49)     | 0.32 (0.35)     | -0.07              |
|             | Stress                           | 0.16 (0.24)     | 0.05 (0.12)     | -0.25              |
|             | Task Impairment                  | 0.72 (0.85)     | 0.39 (0.67)     | -0.15              |
|             | Passive behavior                 | 0.08 (0.27)     | 0.06 (0.31)     | -0.11              |
|             | Unusual behavior (DPDS24)        | 0.26 (0.72)     | 0.18 (0.95)     | -0.22              |

: (\#tab:EMAdescr) Means, standard deviations, and changes in distiributions of daily measures. $SW_\Delta{T1-T2}$: Changes in distributions of raw variables were calculated as $1-Shapiro-Wilk_{T1} - 1-Shapiro-Wilk_{T1}$.

# Discussion

Idiographic networks appeared to be relatively stable within people.

The assessment of stability varied considerably across metrics applied.

There was large variation in network stability across people, which could not be explained by subject-specific variables.

These conclusions are limited in several ways.

### Stability of psychological networks

### Sampling variation / parameter accuracy

-   measurement error

Forking paths - modeling steps taken are somewhat arbitrary, and best practice have yet to be established - detrending, imputation, transformation, missing data - simulation work needed

### Stability of psychological systems

### The counterfactual

-   response shift bias
-   Stabilitiy of a complex system: attractor states, phase transitions, tipping points, research on EWS

### Stability metrics

-   measurement schmeasurement
-   change of sign of edges not assessed by most indices
-   but might be relevant in clinical practice

### Implications for clinical research

-   parameter accuracy should be known to assess whether instability lies in the network structure, or the recovery of that structure in the light of sampling variation

\newpage

# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

\endgroup
